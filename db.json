{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/svm_model.png","path":"images/svm_model.png","modified":0,"renderable":0},{"_id":"themes/hexo-theme-material/source/css/disqus-proxy.css","path":"css/disqus-proxy.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/disqus-proxy.min.css","path":"css/disqus-proxy.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/duoshuo.min.css","path":"css/duoshuo.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/duoshuo.css","path":"css/duoshuo.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/fontawesome.min.css","path":"css/fontawesome.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/gallery.min.css","path":"css/gallery.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/ie-blocker.css","path":"css/ie-blocker.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/material-icons.css","path":"css/material-icons.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify.css","path":"css/prettify.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify.min.css","path":"css/prettify.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/uc.css","path":"css/uc.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/bg.png","path":"img/bg.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/browserstack_logo.png","path":"img/browserstack_logo.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/favicon.ico","path":"img/favicon.ico","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/logo.png","path":"img/logo.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/sidebar_header.png","path":"img/sidebar_header.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/upyun_logo.svg","path":"img/upyun_logo.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.woff","path":"fonts/MaterialIcons-Regular.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.woff2","path":"fonts/MaterialIcons-Regular.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/MathJax.js","path":"js/MathJax.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/Valine.min.js","path":"js/Valine.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/hanabi-browser-bundle.js","path":"js/hanabi-browser-bundle.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/ie-blocker.en.js","path":"js/ie-blocker.en.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/lazyload.min.js","path":"js/lazyload.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/lsloader.js","path":"js/lsloader.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/lsloader.min.js","path":"js/lsloader.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/nprogress.js","path":"js/nprogress.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/prettify.min.js","path":"js/prettify.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/queue.js","path":"js/queue.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/queue.min.js","path":"js/queue.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/smoothscroll.js","path":"js/smoothscroll.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/ie-blocker.zhCN.js","path":"js/ie-blocker.zhCN.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/material.css","path":"css/material.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/material.min.css","path":"css/material.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/style.css","path":"css/style.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/style.min.css","path":"css/style.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/daily_pic.png","path":"img/daily_pic.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.ttf","path":"fonts/MaterialIcons-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.woff","path":"fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.woff2","path":"fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/js.js","path":"js/js.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/js.min.js","path":"js/js.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-cave-dark.min.css","path":"css/prettify/atelier-cave-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-cave-light.min.css","path":"css/prettify/atelier-cave-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-dune-dark.min.css","path":"css/prettify/atelier-dune-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-dune-light.min.css","path":"css/prettify/atelier-dune-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-forest-light.min.css","path":"css/prettify/atelier-forest-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-forest-dark.min.css","path":"css/prettify/atelier-forest-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-heath-dark.min.css","path":"css/prettify/atelier-heath-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-heath-light.min.css","path":"css/prettify/atelier-heath-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-lakeside-dark.min.css","path":"css/prettify/atelier-lakeside-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-plateau-dark.min.css","path":"css/prettify/atelier-plateau-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-savanna-dark.min.css","path":"css/prettify/atelier-savanna-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-plateau-light.min.css","path":"css/prettify/atelier-plateau-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-savanna-light.min.css","path":"css/prettify/atelier-savanna-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-seaside-dark.min.css","path":"css/prettify/atelier-seaside-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-estuary-dark.min.css","path":"css/prettify/atelier-estuary-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-seaside-light.min.css","path":"css/prettify/atelier-seaside-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-sulphurpool-dark.min.css","path":"css/prettify/atelier-sulphurpool-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-sulphurpool-light.min.css","path":"css/prettify/atelier-sulphurpool-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-estuary-light.min.css","path":"css/prettify/atelier-estuary-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/github.min.css","path":"css/prettify/github.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-lakeside-light.min.css","path":"css/prettify/atelier-lakeside-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/hemisu-light.min.css","path":"css/prettify/hemisu-light.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night-blue.min.css","path":"css/prettify/tomorrow-night-blue.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night-bright.min.css","path":"css/prettify/tomorrow-night-bright.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night-eighties.min.css","path":"css/prettify/tomorrow-night-eighties.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night.min.css","path":"css/prettify/tomorrow-night.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow.min.css","path":"css/prettify/tomorrow.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/tranquil-heart.min.css","path":"css/prettify/tranquil-heart.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/vibrant-ink.min.css","path":"css/prettify/vibrant-ink.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/github-v2.min.css","path":"css/prettify/github-v2.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/css/prettify/hemisu-dark.min.css","path":"css/prettify/hemisu-dark.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-bilibili.svg","path":"img/footer/footer_ico-bilibili.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-facebook.svg","path":"img/footer/footer_ico-facebook.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-github.svg","path":"img/footer/footer_ico-github.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-instagram.svg","path":"img/footer/footer_ico-instagram.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-linkedin.svg","path":"img/footer/footer_ico-linkedin.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-telegram.svg","path":"img/footer/footer_ico-telegram.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-tumblr.svg","path":"img/footer/footer_ico-tumblr.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-v2ex.svg","path":"img/footer/footer_ico-v2ex.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-weibo.svg","path":"img/footer/footer_ico-weibo.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-zhihu.svg","path":"img/footer/footer_ico-zhihu.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/gallery/arrow.svg","path":"img/gallery/arrow.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/gallery/close.svg","path":"img/gallery/close.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/gallery/spinner.svg","path":"img/gallery/spinner.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-10.png","path":"img/random/material-10.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-twitter.svg","path":"img/footer/footer_ico-twitter.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-gplus.svg","path":"img/footer/footer_ico-gplus.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-12.png","path":"img/random/material-12.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-19.png","path":"img/random/material-19.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-17.png","path":"img/random/material-17.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-3.png","path":"img/random/material-3.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-6.png","path":"img/random/material-6.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-8.png","path":"img/random/material-8.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-9.png","path":"img/random/material-9.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/FontAwesome.otf","path":"fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-4.png","path":"img/random/material-4.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.eot","path":"fonts/MaterialIcons-Regular.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.eot","path":"fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.ttf","path":"fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/js/gallery/gallery.js","path":"js/gallery/gallery.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-1.png","path":"img/random/material-1.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-13.png","path":"img/random/material-13.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-14.png","path":"img/random/material-14.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-11.png","path":"img/random/material-11.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-15.png","path":"img/random/material-15.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-16.png","path":"img/random/material-16.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-18.png","path":"img/random/material-18.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-5.png","path":"img/random/material-5.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-7.png","path":"img/random/material-7.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/random/material-2.png","path":"img/random/material-2.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.svg","path":"fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Black.ttf","path":"fonts/Roboto-Black.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Bold.ttf","path":"fonts/Roboto-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Medium.ttf","path":"fonts/Roboto-Medium.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Light.ttf","path":"fonts/Roboto-Light.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Regular.ttf","path":"fonts/Roboto-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Thin.ttf","path":"fonts/Roboto-Thin.ttf","modified":0,"renderable":1}],"Cache":[{"_id":"themes/hexo-theme-material/CONTRIBUTING.md","hash":"148f555e47d4725fe1faac775107a4d7b03f7136","modified":1562776676358},{"_id":"themes/hexo-theme-material/CONTRIBUTING.zh-cn.md","hash":"ef3ccef0451d6ac616b3a35fbfedb6abd35e6b41","modified":1562776676359},{"_id":"themes/hexo-theme-material/LICENSE","hash":"12d81f50767d4e09aa7877da077ad9d1b915d75b","modified":1562776676360},{"_id":"themes/hexo-theme-material/README.md","hash":"408e36745a8aeb187a25f309752c5e7da66f7e67","modified":1562776676360},{"_id":"themes/hexo-theme-material/_config.template.yml","hash":"909c9b66c782311a0fe16bca4e75dc13e1b289ea","modified":1562776676361},{"_id":"themes/hexo-theme-material/_config.yml","hash":"0e392218aaff7a8cb5fb175198efe85032b99f16","modified":1562776676362},{"_id":"themes/hexo-theme-material/contributing.json","hash":"1bc0871b1c7822b82533b614090ac0ab7c55282c","modified":1562776676363},{"_id":"themes/hexo-theme-material/lint.sh","hash":"49c3a65f8ca65754ec7fefcd2dcb6adc187f3856","modified":1562776676437},{"_id":"themes/hexo-theme-material/package.json","hash":"e00885ee25ac548685af9869cf4cf895118a744c","modified":1562776676437},{"_id":"source/_posts/svm从原理到实现.md","hash":"98972eabaebf9c32c0de74703d3ee5dbbd2d9fb7","modified":1562777982080},{"_id":"source/_posts/让机器读懂文章-pLSA模型推导及实现.md","hash":"8b21c79f7dd32275cb077cd03dbff44737a5b69a","modified":1562783247391},{"_id":"source/images/svm_model.png","hash":"26a4914014238720238426dbfb0acb2397540bd5","modified":1562776676356},{"_id":"themes/hexo-theme-material/languages/ar.yml","hash":"472d71f052e08f3c03b15dd67d11ad41f2eee7bf","modified":1562776676364},{"_id":"themes/hexo-theme-material/languages/de.yml","hash":"bce37d066ffa82f3e249d41d0ee883c913cc2c5f","modified":1562776676365},{"_id":"themes/hexo-theme-material/languages/en.yml","hash":"b59136a1b4d0a77e550b0e7e2e430cac44230dd3","modified":1562776676366},{"_id":"themes/hexo-theme-material/languages/es.yml","hash":"d35f5411bc87277cc2d3a58d9499ddb9cfd46f1b","modified":1562776676367},{"_id":"themes/hexo-theme-material/languages/fr.yml","hash":"f456cf31a72d97f2f18e3bb6cf735285d2b9d2c5","modified":1562776676368},{"_id":"themes/hexo-theme-material/languages/ja.yml","hash":"768b8330c9c73287efd475e68741ce4ebad29fd1","modified":1562776676368},{"_id":"themes/hexo-theme-material/languages/ms.yml","hash":"237a39bbfcce33e7b918f6c5dc0f01bc79900262","modified":1562776676369},{"_id":"themes/hexo-theme-material/languages/nl_NL.yml","hash":"b71e59807716185627d6b9b84e44a79401df639f","modified":1562776676370},{"_id":"themes/hexo-theme-material/languages/pt-BR.yml","hash":"a070c2c4d0d3d54f8ca70513cff73c3f7c306db1","modified":1562776676371},{"_id":"themes/hexo-theme-material/languages/ru.yml","hash":"fbff2cf48dbde45adcad781e2fd6c30b523a4ac1","modified":1562776676372},{"_id":"themes/hexo-theme-material/languages/zh-CN.yml","hash":"c188cad1a16ab0651e2d2d03cb3fa79962cf65ff","modified":1562776676373},{"_id":"themes/hexo-theme-material/languages/zh-TW.yml","hash":"ec55953f0330f81bf1ffb37ff34de258dfda642a","modified":1562776676374},{"_id":"themes/hexo-theme-material/layout/index.ejs","hash":"aca1abb741f891776913c8ea2e6ff626a0ea5736","modified":1562776676434},{"_id":"themes/hexo-theme-material/layout/layout.ejs","hash":"94f66850b815a262c0f8ff112a32a0a6f43066e3","modified":1562776676435},{"_id":"themes/hexo-theme-material/layout/post.ejs","hash":"4dd572a9e84f3a6baa5e3f16d270e58e3cd31a23","modified":1562776676436},{"_id":"themes/hexo-theme-material/scripts/helper.js","hash":"e7111a8b1f0ab5bf3466378c48c260a4f6e527d6","modified":1562776676438},{"_id":"themes/hexo-theme-material/layout/_partial/Isolation-post-info.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1562776676375},{"_id":"themes/hexo-theme-material/scripts/lib/font_lsload.js","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1562776676440},{"_id":"source/_posts/images/svm_model.png","hash":"26a4914014238720238426dbfb0acb2397540bd5","modified":1562777982079},{"_id":"source/_posts/svm从原理到实现/svm_model.gif","hash":"dd200e24bdcb73703b70d3448c6bbcfa796f956c","modified":1562777982082},{"_id":"source/_posts/svm从原理到实现/svm_model.png","hash":"26a4914014238720238426dbfb0acb2397540bd5","modified":1562777982084},{"_id":"themes/hexo-theme-material/layout/_partial/Isolation-post_entry.ejs","hash":"134dc82320b7aed7d4d78960be63e16c5c4a30fb","modified":1562776676375},{"_id":"themes/hexo-theme-material/layout/_partial/Paradox-post-info.ejs","hash":"125cfa5cd9e6e1ca5e958026fdd42f3c3141e34f","modified":1562776676376},{"_id":"themes/hexo-theme-material/layout/_partial/Paradox-post-thumbnail.ejs","hash":"6f1e9a85c089ce98a36a2954839fb9ce3e53739e","modified":1562776676377},{"_id":"themes/hexo-theme-material/layout/_partial/Paradox-post_entry-thumbnail.ejs","hash":"4d740eba338517d4e10d011a157cdefad45a8e1f","modified":1562776676378},{"_id":"themes/hexo-theme-material/layout/_partial/Paradox-post_entry.ejs","hash":"5f4d67e5bd70f635203706cf344b036d891073e6","modified":1562776676379},{"_id":"themes/hexo-theme-material/layout/_partial/Paradox-search.ejs","hash":"18a6971b04feccd124a096b8c7cecf1fd4bb914e","modified":1562776676380},{"_id":"themes/hexo-theme-material/layout/_partial/blog_info.ejs","hash":"5e95796e6f9a81163554ca4198573860f7328d4e","modified":1562776676381},{"_id":"themes/hexo-theme-material/layout/_partial/comment.ejs","hash":"c9fb1f98a18ca484cb52d60e2ad2bad25b56dfb2","modified":1562776676382},{"_id":"themes/hexo-theme-material/layout/_partial/config_css.ejs","hash":"2b1e27faa0446a5e756e61ddf3e969e50948f1ce","modified":1562776676382},{"_id":"themes/hexo-theme-material/layout/_partial/config_font.ejs","hash":"730abeb681758ce288d5541930c46bc4b041a0b1","modified":1562776676383},{"_id":"themes/hexo-theme-material/layout/_partial/daily_pic.ejs","hash":"e780fbdb79b5e27091c408545cfd5b64892c9b01","modified":1562776676384},{"_id":"themes/hexo-theme-material/layout/_partial/footer-left.ejs","hash":"372cdf718e01fea2736b8e427e57bfcfaa8a557f","modified":1562776676385},{"_id":"themes/hexo-theme-material/layout/_partial/footer-option.ejs","hash":"be20394eaeaf2d20db28946b948962c839da6ea9","modified":1562776676386},{"_id":"themes/hexo-theme-material/layout/_partial/footer.ejs","hash":"530626c347882579d09d71df68993e25076ca8e2","modified":1562776676386},{"_id":"themes/hexo-theme-material/layout/_partial/footer_top.ejs","hash":"9eaace4feb951c96c0033e7271497f3f300d2476","modified":1562776676387},{"_id":"themes/hexo-theme-material/layout/_partial/head.ejs","hash":"8167f995c7cc21a6a8ddbfbdd03f2f74a7bd904d","modified":1562776676388},{"_id":"themes/hexo-theme-material/layout/_partial/import_js.ejs","hash":"961b8a0059875e4044fe80bbe91ca6a225f113e5","modified":1562776676389},{"_id":"themes/hexo-theme-material/layout/_partial/isolate_info.ejs","hash":"b8ec76716bfa2e6513b4df6814fe8676536a94c1","modified":1562776676391},{"_id":"themes/hexo-theme-material/layout/_partial/post-content.ejs","hash":"ad626e3b60bc4a17bacff02cf9b0a8beaba2ad1e","modified":1562776676392},{"_id":"themes/hexo-theme-material/layout/_partial/post-header.ejs","hash":"b0b8973c48db6376a24d4b4b1d2eb15d18d6508c","modified":1562776676393},{"_id":"themes/hexo-theme-material/layout/_partial/post-info-share.ejs","hash":"9f28d62bf728c2bd89411688426a65d7ee55400c","modified":1562776676393},{"_id":"themes/hexo-theme-material/layout/_partial/post-nav.ejs","hash":"3b6d4568cc46f60c697ad9ec85a4aa5971f3eecc","modified":1562776676394},{"_id":"themes/hexo-theme-material/layout/_partial/sidebar-footer.ejs","hash":"6c3486b846473e0d58666f7a8720f5bf4a14e030","modified":1562776676395},{"_id":"themes/hexo-theme-material/layout/_partial/sidebar-footer_image.ejs","hash":"b9157d2072028a1db3c3419f76bde6637e85cf0e","modified":1562776676396},{"_id":"themes/hexo-theme-material/layout/_partial/sidebar-header.ejs","hash":"06295e01092f55504d30a343c3fdc5091280e495","modified":1562776676397},{"_id":"themes/hexo-theme-material/layout/_partial/sidebar-navigation.ejs","hash":"ff44901fdfdd952174b0d22e86df7163d7fba9ba","modified":1562776676397},{"_id":"themes/hexo-theme-material/layout/_partial/sidebar.ejs","hash":"c5ce6136e82895cb80dab8a918a7cdf2fe820fea","modified":1562776676398},{"_id":"themes/hexo-theme-material/layout/_partial/structured-data.ejs","hash":"e845df290185dc300cc4edcc08b50fddc5b6909b","modified":1562776676399},{"_id":"themes/hexo-theme-material/layout/_partial/toc_button.ejs","hash":"688c3fc12e2548ff27fe60688f79dcce2881fd50","modified":1562776676400},{"_id":"themes/hexo-theme-material/layout/_partial/isolate-sns_list.ejs","hash":"fc5f03ebb847f85975676a9dfee8870e7c908008","modified":1562776676390},{"_id":"themes/hexo-theme-material/layout/_widget/dnsprefetch.ejs","hash":"5e4c5359d69a64042183db13f6dd771b1f7f6b31","modified":1562776676423},{"_id":"themes/hexo-theme-material/layout/_widget/leancloud-like.ejs","hash":"e4780fe3bbb049db38d694fc18dee13d799bd51d","modified":1562776676424},{"_id":"themes/hexo-theme-material/layout/_widget/leancloud-views.ejs","hash":"211dc183b8e84f71b2c25b3ac6659d162d81662b","modified":1562776676425},{"_id":"themes/hexo-theme-material/layout/_widget/leancloud-views_num.ejs","hash":"e27baba6a2de406463735d276606b15fb40f5eba","modified":1562776676425},{"_id":"themes/hexo-theme-material/layout/_widget/mathjax.ejs","hash":"b68befe1fea84739c8429c344e570a8bc0357401","modified":1562776676426},{"_id":"themes/hexo-theme-material/layout/_widget/nprogress.ejs","hash":"901a64600854b312209287c702278183600e06b9","modified":1562776676427},{"_id":"themes/hexo-theme-material/layout/_widget/page-gallery.ejs","hash":"81b9410deef7a83ef5bc7cd18ad042df70d70b94","modified":1562776676428},{"_id":"themes/hexo-theme-material/layout/_widget/page-links.ejs","hash":"0ebe18e4326f921d6010df8479a08c2d403ba717","modified":1562776676429},{"_id":"themes/hexo-theme-material/layout/_widget/page-tagcloud.ejs","hash":"e71de74e4067cc4e6aef1e09ac429c92bcd178b3","modified":1562776676430},{"_id":"themes/hexo-theme-material/layout/_widget/page-timeline.ejs","hash":"9fa0195e08d9fd40aa0333e9279c98bc65acf604","modified":1562776676430},{"_id":"themes/hexo-theme-material/layout/_widget/qrcode.ejs","hash":"3212e5d29fe8490c5d9a844ec9c2ce9925532de8","modified":1562776676431},{"_id":"themes/hexo-theme-material/layout/_widget/search-local-js.ejs","hash":"f42cc040adf47fc7d74f64b0be3c3230e8a3339e","modified":1562776676432},{"_id":"themes/hexo-theme-material/layout/_widget/search-swiftype-js.ejs","hash":"7ad1e843e620ccd9b3c041dccfdcee97921247a1","modified":1562776676433},{"_id":"themes/hexo-theme-material/scripts/lib/css_lsload.js","hash":"179f5f5e3297a7fb7d90545ddd94eb468a11046e","modified":1562776676439},{"_id":"themes/hexo-theme-material/scripts/lib/get_file_hex.js","hash":"eb3b9a45f8ca45ef40d5421baef7d4484023982c","modified":1562776676441},{"_id":"themes/hexo-theme-material/scripts/lib/js_hex.js","hash":"2704583aa036d538544ce31c2e924c0c125309dd","modified":1562776676441},{"_id":"themes/hexo-theme-material/scripts/lib/js_lsload.js","hash":"72f885b13fe0028a0e2acb7168dcc66e39ea1592","modified":1562776676442},{"_id":"themes/hexo-theme-material/scripts/lib/path_for.js","hash":"f944e3b53a468962121aa3357cc0bc18ac27a34c","modified":1562776676443},{"_id":"themes/hexo-theme-material/source/css/disqus-proxy.css","hash":"770776d8cec27cd5661bdfd59eff9af263439989","modified":1562776676444},{"_id":"themes/hexo-theme-material/source/css/disqus-proxy.min.css","hash":"3f8f99f71d361302288b0ba11fd36072564b08c2","modified":1562776676445},{"_id":"themes/hexo-theme-material/source/css/duoshuo.min.css","hash":"89a30544b8b01d061da51c40f2af702a7969de5e","modified":1562776676447},{"_id":"themes/hexo-theme-material/source/css/duoshuo.css","hash":"32a02eaa01ff7b66fd9df307b0d33d52810096be","modified":1562776676446},{"_id":"themes/hexo-theme-material/source/css/fontawesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1562776676448},{"_id":"themes/hexo-theme-material/source/css/gallery.min.css","hash":"c5333ca835aae49239d809130a7b281af745729e","modified":1562776676449},{"_id":"themes/hexo-theme-material/source/css/ie-blocker.css","hash":"dddce7e6250a449291888ae7865697282a213b14","modified":1562776676450},{"_id":"themes/hexo-theme-material/source/css/material-icons.css","hash":"f6f95fe5190f3c65931847246621fb83754eb00c","modified":1562776676451},{"_id":"themes/hexo-theme-material/source/css/prettify.css","hash":"c395f20ee64e80c2b6b15c7dade02f9aaaeab2c8","modified":1562776676454},{"_id":"themes/hexo-theme-material/source/css/prettify.min.css","hash":"62edd8f08656463b0e077dcf893faa3cc8eb5fe4","modified":1562776676455},{"_id":"themes/hexo-theme-material/source/css/uc.css","hash":"1e0977a2c9bdf721cc05654dfc025dd250655852","modified":1562776676492},{"_id":"themes/hexo-theme-material/source/img/avatar.png","hash":"bf483b0d495dbbcfb308348a945818e1c1cc9696","modified":1562776676532},{"_id":"themes/hexo-theme-material/source/img/bg.png","hash":"a32f9717e19e821a4030ade551dc2917c889fcd8","modified":1562776676533},{"_id":"themes/hexo-theme-material/source/img/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1562776676534},{"_id":"themes/hexo-theme-material/source/img/favicon.ico","hash":"e502fbc644a8f5bde6724370697513899746666f","modified":1562776676536},{"_id":"themes/hexo-theme-material/source/img/favicon.png","hash":"b1bcc84cedb2a618e8db93559ce7d58f9274085d","modified":1562776676537},{"_id":"themes/hexo-theme-material/source/img/logo.png","hash":"b1bcc84cedb2a618e8db93559ce7d58f9274085d","modified":1562776676553},{"_id":"themes/hexo-theme-material/source/img/sidebar_header.png","hash":"c47f4d39f421c0a950279d050ae82f9ae6dd19ff","modified":1562776676576},{"_id":"themes/hexo-theme-material/source/img/upyun_logo.svg","hash":"1f118b2b9c54f431d5e731ccf316ceefe605ba67","modified":1562776676577},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.woff","hash":"c6c953c2ccb2ca9abb21db8dbf473b5a435f0082","modified":1562776676498},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.woff2","hash":"09963592e8c953cc7e14e3fb0a5b05d5042e8435","modified":1562776676498},{"_id":"themes/hexo-theme-material/source/js/MathJax.js","hash":"a21703b5848325a902c9b39bbf3ca6490d3e1b1b","modified":1562776676578},{"_id":"themes/hexo-theme-material/source/js/Valine.min.js","hash":"6a287a99a772a0ea8f98b133523429c9250cc67f","modified":1562776676579},{"_id":"themes/hexo-theme-material/source/js/hanabi-browser-bundle.js","hash":"d646647bda386140c8315d60e3ff4ddbdb15c1ea","modified":1562776676582},{"_id":"themes/hexo-theme-material/source/js/ie-blocker.en.js","hash":"96ca8e677a12048d099319ebdf01983ddc6ca80c","modified":1562776676583},{"_id":"themes/hexo-theme-material/source/js/lazyload.min.js","hash":"5348fd7aa4dbefac9d21091c9fd5e263563b5540","modified":1562776676588},{"_id":"themes/hexo-theme-material/source/js/lsloader.js","hash":"2b14e57784fb6b5f58d71584189c61af45f393e8","modified":1562776676589},{"_id":"themes/hexo-theme-material/source/js/lsloader.min.js","hash":"1a68a8d267948ea8475245b7d365a1a1bd8f732e","modified":1562776676590},{"_id":"themes/hexo-theme-material/source/js/nprogress.js","hash":"a3058d4b6afb5d7a14e5afcbb88f778de35864f0","modified":1562776676591},{"_id":"themes/hexo-theme-material/source/js/prettify.min.js","hash":"69908fe0a09cee107c25cb5d769b861723e7b7bb","modified":1562776676592},{"_id":"themes/hexo-theme-material/source/js/queue.js","hash":"dd252616b568b71c222d9cfc859bfe52738e576a","modified":1562776676593},{"_id":"themes/hexo-theme-material/source/js/queue.min.js","hash":"21aab782ca33efbb1386cc960b6be0a02106760d","modified":1562776676594},{"_id":"themes/hexo-theme-material/source/js/smoothscroll.js","hash":"df56a1c84191a62750ae820943377b6775fca0e2","modified":1562776676595},{"_id":"themes/hexo-theme-material/source/js/ie-blocker.zhCN.js","hash":"0ed49b0ec1d1924b128fbd97fca2cf7af7856fdf","modified":1562776676583},{"_id":"themes/hexo-theme-material/source/css/material.css","hash":"068e2b00f686157b6e8b78b9b808112adbedf4de","modified":1562776676453},{"_id":"themes/hexo-theme-material/source/css/material.min.css","hash":"1a19febb9214ab689b02f5bb8ccb23579e6c1181","modified":1562776676454},{"_id":"themes/hexo-theme-material/source/css/style.css","hash":"02ea82d87b95d6d89472624e9c23be551289a1d3","modified":1562776676490},{"_id":"themes/hexo-theme-material/source/css/style.min.css","hash":"04f492093ea96e176438510c38d28f5450ebc7de","modified":1562776676491},{"_id":"themes/hexo-theme-material/source/img/daily_pic.png","hash":"5e9a5f6a134889d0242e69061837f2032416d7ce","modified":1562776676535},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.ttf","hash":"fc05de31234e0090f7ddc28ce1b23af4026cb1da","modified":1562776676497},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1562776676528},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1562776676529},{"_id":"themes/hexo-theme-material/source/js/jquery.min.js","hash":"00073d6597d2760b81387274a9ec56b9d5cb1552","modified":1562776676585},{"_id":"themes/hexo-theme-material/source/js/js.js","hash":"64b3f20e7138674ecf21e6e3982565ea63feae26","modified":1562776676586},{"_id":"themes/hexo-theme-material/layout/_widget/analytics/baidu-analytics.ejs","hash":"3866a7fead3c1f94a517f1f9d629f092670b1520","modified":1562776676401},{"_id":"themes/hexo-theme-material/layout/_widget/analytics/cnzz-analytics.ejs","hash":"1765e3dcd92961292f40d1812e593186c77b17ef","modified":1562776676402},{"_id":"themes/hexo-theme-material/source/js/js.min.js","hash":"709d347d3be033b841de0493b7cf532b594bb1f6","modified":1562776676587},{"_id":"themes/hexo-theme-material/layout/_widget/analytics/google-analytics.ejs","hash":"3b10ebf524baf0c24b22dcd110b39d15c5acb9b5","modified":1562776676403},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-cave-dark.min.css","hash":"cb0156cdc36500a26b232ae1c81fdc880eba85e7","modified":1562776676456},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-cave-light.min.css","hash":"4b62dc45aa351b071d6a434dc54fe8c2e15c85cc","modified":1562776676457},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-dune-dark.min.css","hash":"c5094d99ca0e619d97860c88211bf908fdf830b1","modified":1562776676460},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-dune-light.min.css","hash":"b3ad98483e4d5bde72d52a15423d98e0d086db09","modified":1562776676461},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-forest-light.min.css","hash":"3532f6e86bf4afbba05f7a074b791b73174f9622","modified":1562776676464},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-forest-dark.min.css","hash":"9296b851a5b66785a60afa5da5fe9080bda96bf5","modified":1562776676463},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-heath-dark.min.css","hash":"954309acd7918422382a3ff2f9c2988aec0ff956","modified":1562776676467},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-heath-light.min.css","hash":"a67199fa580b3aa2df031e5d2028929d29ca3b45","modified":1562776676468},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-lakeside-dark.min.css","hash":"18575fc6dff855e395a39d0383d2f18807091f0d","modified":1562776676469},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-plateau-dark.min.css","hash":"137e3c499a720da3c1d57b4dc53264b1d623e1c5","modified":1562776676471},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-savanna-dark.min.css","hash":"fba92c652fd6704422b8f2bbc11706805a6faed0","modified":1562776676473},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-plateau-light.min.css","hash":"153801640fdcbb74c0de3f15345110f2210eb991","modified":1562776676471},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-savanna-light.min.css","hash":"d9425ffb7c60d646190c22b9a5f72091ee5f9ace","modified":1562776676474},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-seaside-dark.min.css","hash":"e0e6bbacc75a349b1e49c236d374b0e42f1fd485","modified":1562776676475},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-estuary-dark.min.css","hash":"7e3a065cafeb3acc1d7178f64ef4265f5d5ad2b9","modified":1562776676462},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-seaside-light.min.css","hash":"732750b75389c1c49204f37705e6abeee40ce64f","modified":1562776676477},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-sulphurpool-dark.min.css","hash":"015a35dddaee153fa8bb71d7f3818a6ba4d120d8","modified":1562776676478},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-sulphurpool-light.min.css","hash":"ab1a6200eab648cab443c3df77fde9b237ef27b6","modified":1562776676479},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-estuary-light.min.css","hash":"1d12d8f7fa9c122a186ee76fdf681c191a68f104","modified":1562776676462},{"_id":"themes/hexo-theme-material/source/css/prettify/github.min.css","hash":"19cf828225288fa5c006f1d8f66c39d11f4ef7f2","modified":1562776676480},{"_id":"themes/hexo-theme-material/source/css/prettify/atelier-lakeside-light.min.css","hash":"e20e8ac64432fa1aa6f74792b58196af7cf79c12","modified":1562776676470},{"_id":"themes/hexo-theme-material/source/css/prettify/hemisu-light.min.css","hash":"b2556ff41e513fd13d032ec84a37ee260a905815","modified":1562776676483},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night-blue.min.css","hash":"c442728d96485bcf816151fe6bd96993aae09852","modified":1562776676484},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night-bright.min.css","hash":"cf251fd3edfd736695272a0f1b41d509b7bb1fb9","modified":1562776676485},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night-eighties.min.css","hash":"6ce259d674bb4edda23eea32b2379be17d0e0e6e","modified":1562776676486},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow-night.min.css","hash":"d989206d124035494acb4b0cdc7fbc89f3b7d108","modified":1562776676486},{"_id":"themes/hexo-theme-material/source/css/prettify/tomorrow.min.css","hash":"b2c6d610b77f0273fefab5aa4ad26a7f58956f87","modified":1562776676487},{"_id":"themes/hexo-theme-material/source/css/prettify/tranquil-heart.min.css","hash":"0f6eefbdda8e410832e9c516a5dd19899217ef06","modified":1562776676488},{"_id":"themes/hexo-theme-material/source/css/prettify/vibrant-ink.min.css","hash":"c265bac6c31cf622b536b29c8a6bc46955d6fe63","modified":1562776676489},{"_id":"themes/hexo-theme-material/source/css/prettify/github-v2.min.css","hash":"57630621d20842a529bdea7b17fc90f520e562ef","modified":1562776676480},{"_id":"themes/hexo-theme-material/source/css/prettify/hemisu-dark.min.css","hash":"a671248cfd573292026d2174817e82e593691052","modified":1562776676482},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-bilibili.svg","hash":"1a007ae30d69aa597f589edb4ee0638a9814c988","modified":1562776676538},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-facebook.svg","hash":"74b3b3c6bd1d76b7eaaf75d36ac929b11a5a3e82","modified":1562776676539},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-github.svg","hash":"5f1f9f53e6a87ad674108c6bd16e424a1e888c61","modified":1562776676540},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-instagram.svg","hash":"294c511e62063ea49f61e23958ab27d643ba0228","modified":1562776676541},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-linkedin.svg","hash":"9831c86352ec5ff283a3277d033120f86388c277","modified":1562776676542},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-telegram.svg","hash":"413d66e40ca476deeb49364935d49d2f7839cdfd","modified":1562776676543},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-tumblr.svg","hash":"11daf4fa4220787306fc21a879429e98b7db8d03","modified":1562776676544},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-v2ex.svg","hash":"c5ffaf67a97e534c266d1585a9a3b56f1bfe3052","modified":1562776676546},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-weibo.svg","hash":"26d0cdb77f0c4afd60111176167eacfa222bc4c1","modified":1562776676546},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-zhihu.svg","hash":"d3f8da320fffefc5144822665dfe17d25af4061c","modified":1562776676547},{"_id":"themes/hexo-theme-material/source/img/gallery/arrow.svg","hash":"144d73877e52acc5068bc0c9d1e69ef450e69f26","modified":1562776676549},{"_id":"themes/hexo-theme-material/source/img/gallery/close.svg","hash":"2690088060811f01c9360df75be80070156ff176","modified":1562776676551},{"_id":"themes/hexo-theme-material/source/img/gallery/spinner.svg","hash":"fc9d1cd1118ac896d4f5326e110a653f3ea32b11","modified":1562776676552},{"_id":"themes/hexo-theme-material/source/img/random/material-10.png","hash":"363466a376e4df9e61acc904cd25f3c7ae1a7280","modified":1562776676556},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-twitter.svg","hash":"58df7777d6fcee8fa3c42453c091714bb3f97c95","modified":1562776676545},{"_id":"themes/hexo-theme-material/source/img/footer/footer_ico-gplus.svg","hash":"b50274133ab263bcacdf729871d0446b615ac984","modified":1562776676541},{"_id":"themes/hexo-theme-material/source/img/random/material-12.png","hash":"d020b3d42542715c7ae95b3d8603fe3180bfe8f3","modified":1562776676558},{"_id":"themes/hexo-theme-material/source/img/random/material-19.png","hash":"768ed1a4966e2e418cb00f6b36d2fc9058328eb3","modified":1562776676566},{"_id":"themes/hexo-theme-material/source/img/random/material-17.png","hash":"ece82810e31f711576db598c845c3d97bd49fe67","modified":1562776676564},{"_id":"themes/hexo-theme-material/source/img/random/material-3.png","hash":"848eaa70b9b0cd7a2204c78e8aa324d8f96bb097","modified":1562776676568},{"_id":"themes/hexo-theme-material/source/img/random/material-6.png","hash":"2f841e0c064fecb607ad1e149662a0c96d9e725d","modified":1562776676571},{"_id":"themes/hexo-theme-material/source/img/random/material-8.png","hash":"57db542d526ef6866cb34e261096e93a0e6f3a82","modified":1562776676574},{"_id":"themes/hexo-theme-material/source/img/random/material-9.png","hash":"840319c4d1f38fb8df79eb4669ed2e14d89fd680","modified":1562776676575},{"_id":"themes/hexo-theme-material/source/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1562776676493},{"_id":"themes/hexo-theme-material/source/img/random/material-4.png","hash":"b475dfbf67a076a4e17a5527fd1973b1d4adac07","modified":1562776676569},{"_id":"themes/hexo-theme-material/source/fonts/MaterialIcons-Regular.eot","hash":"26fb8cecb5512223277b4d290a24492a0f09ede1","modified":1562776676495},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1562776676524},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1562776676527},{"_id":"themes/hexo-theme-material/source/js/gallery/gallery.js","hash":"8ee48312a183b42a9886211a0ec825ea0d041301","modified":1562776676581},{"_id":"themes/hexo-theme-material/layout/_widget/comment/livere/common.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1562776676419},{"_id":"themes/hexo-theme-material/layout/_widget/comment/valine/common.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1562776676421},{"_id":"themes/hexo-theme-material/source/img/random/material-1.png","hash":"4839299eaa4db7272befa7b824e54b647fbbfc44","modified":1562776676554},{"_id":"themes/hexo-theme-material/source/img/random/material-13.png","hash":"1a8378db3121b583485e2b939cb1aa0e0b14b0c8","modified":1562776676559},{"_id":"themes/hexo-theme-material/source/img/random/material-14.png","hash":"b4f65b601960138c69f57171b0ddd55895483f45","modified":1562776676560},{"_id":"themes/hexo-theme-material/source/img/random/material-11.png","hash":"ce20b0ad08a248c036115374f2edb7301ff60b72","modified":1562776676557},{"_id":"themes/hexo-theme-material/source/img/random/material-15.png","hash":"36b9937cf3810e4970902b78797ad29b0831f065","modified":1562776676561},{"_id":"themes/hexo-theme-material/source/img/random/material-16.png","hash":"ade7f75200d3fb38326e3cf1e9f1a812fb12a43b","modified":1562776676563},{"_id":"themes/hexo-theme-material/source/img/random/material-18.png","hash":"4b98204abe36ecd3f30678d2c22059130e0db328","modified":1562776676565},{"_id":"themes/hexo-theme-material/source/img/random/material-5.png","hash":"5041ebd073a139c67f8ed271e74c967c7eb9c5be","modified":1562776676570},{"_id":"themes/hexo-theme-material/source/img/random/material-7.png","hash":"5c49ff3c064aaeb21227c2bd98b5ae422ddca84c","modified":1562776676573},{"_id":"themes/hexo-theme-material/source/img/random/material-2.png","hash":"faba2ce69c19d6c1dac392dd10b054e0061f6fb7","modified":1562776676567},{"_id":"themes/hexo-theme-material/layout/_widget/comment/changyan/common.ejs","hash":"40e1fc76d6b7f64e226693fb2fe1a6bb17bae245","modified":1562776676404},{"_id":"themes/hexo-theme-material/layout/_widget/comment/changyan/enter.ejs","hash":"e3cfb4f37ea35457f112f3e822e130c930086497","modified":1562776676405},{"_id":"themes/hexo-theme-material/layout/_widget/comment/changyan/main.ejs","hash":"77539ff32cc9d1204b848e01b5277fff5cbd61e0","modified":1562776676406},{"_id":"themes/hexo-theme-material/layout/_widget/comment/disqus/common.ejs","hash":"c11cfceb0906a96399dede5da01ff7fe4787f8a5","modified":1562776676407},{"_id":"themes/hexo-theme-material/layout/_widget/comment/disqus/enter.ejs","hash":"39192034766349e47967da63184f9104fdded2ab","modified":1562776676408},{"_id":"themes/hexo-theme-material/layout/_widget/comment/disqus/main.ejs","hash":"21e0eeff664191b818d7a0071ae7edcdfc270442","modified":1562776676409},{"_id":"themes/hexo-theme-material/layout/_widget/comment/disqus_click/common.ejs","hash":"d243f576b366a62191066459efcc6fd0ab79d00a","modified":1562776676410},{"_id":"themes/hexo-theme-material/layout/_widget/comment/disqus_click/enter.ejs","hash":"d82f0296f8bae25223ec44e6e05b817d3a234884","modified":1562776676411},{"_id":"themes/hexo-theme-material/layout/_widget/comment/disqus_click/main.ejs","hash":"f53de208ca46c669a868a1922488e39509c6fe3b","modified":1562776676412},{"_id":"themes/hexo-theme-material/layout/_widget/comment/gitalk/common.ejs","hash":"f739897518011e1b3de7807c8c5d734984711282","modified":1562776676413},{"_id":"themes/hexo-theme-material/layout/_widget/comment/gitalk/enter.ejs","hash":"4d70d76465469a57def29a221962a5520fb34ebe","modified":1562776676414},{"_id":"themes/hexo-theme-material/layout/_widget/comment/gitalk/main.ejs","hash":"1ee7a7b2b9b5ae8c4fa8c4b09c7973b9e085bdf2","modified":1562776676415},{"_id":"themes/hexo-theme-material/layout/_widget/comment/gitment/common.ejs","hash":"9c6c8d1b448c32afb01c2d0351e87f4d4a17ec3c","modified":1562776676416},{"_id":"themes/hexo-theme-material/layout/_widget/comment/gitment/enter.ejs","hash":"46d904fde9233694b95c6a3d91b9a2b7a6805850","modified":1562776676417},{"_id":"themes/hexo-theme-material/layout/_widget/comment/gitment/main.ejs","hash":"e622660eda38cda05847aadc2a3e31a228fc519b","modified":1562776676418},{"_id":"themes/hexo-theme-material/layout/_widget/comment/livere/main.ejs","hash":"1c4be9ba104a8cbcc11d45f11bf8cfe7704b93a5","modified":1562776676420},{"_id":"themes/hexo-theme-material/layout/_widget/comment/livere/enter.ejs","hash":"194b7bb581a3b8608a7ab135b6953d7908f51cc8","modified":1562776676419},{"_id":"themes/hexo-theme-material/layout/_widget/comment/valine/enter.ejs","hash":"ab528aad46237d9e7f1c5b4b2b310dd628b2de63","modified":1562776676421},{"_id":"themes/hexo-theme-material/layout/_widget/comment/valine/main.ejs","hash":"3d5d8559e6ad4ffb58a61d96439b2718eb9999b6","modified":1562776676422},{"_id":"themes/hexo-theme-material/source/img/avatar.jpg","hash":"ad463ca55f48284e30c654c49d0e64beac6ca004","modified":1562776676531},{"_id":"themes/hexo-theme-material/source/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1562776676526},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Black.ttf","hash":"0244e6497a51fb8a38ca7e6fe297b066e2e09af5","modified":1562776676502},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Bold.ttf","hash":"d1864343b543978bd491d40c80010cea50c1b7bf","modified":1562776676506},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Medium.ttf","hash":"3965419aab480c184f66bc5e39c1719a373a4ef6","modified":1562776676514},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Light.ttf","hash":"b9ea2eaf26ff8fdcb5aee3e0c2c7a6084ebb6aac","modified":1562776676510},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Regular.ttf","hash":"06691e103d4d3ce1f1108d9b7d21254b714a41f8","modified":1562776676518},{"_id":"themes/hexo-theme-material/source/fonts/Roboto-Thin.ttf","hash":"ed5101c3a800f35e925603a406e0c2dc5278b96c","modified":1562776676522},{"_id":"public/images/svm_model.png","hash":"26a4914014238720238426dbfb0acb2397540bd5","modified":1562783112122},{"_id":"public/img/avatar.png","hash":"bf483b0d495dbbcfb308348a945818e1c1cc9696","modified":1562783112122},{"_id":"public/img/bg.png","hash":"a32f9717e19e821a4030ade551dc2917c889fcd8","modified":1562783112123},{"_id":"public/img/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1562783112124},{"_id":"public/img/favicon.ico","hash":"e502fbc644a8f5bde6724370697513899746666f","modified":1562783112124},{"_id":"public/img/favicon.png","hash":"b1bcc84cedb2a618e8db93559ce7d58f9274085d","modified":1562783112124},{"_id":"public/img/logo.png","hash":"b1bcc84cedb2a618e8db93559ce7d58f9274085d","modified":1562783112125},{"_id":"public/img/sidebar_header.png","hash":"c47f4d39f421c0a950279d050ae82f9ae6dd19ff","modified":1562783112126},{"_id":"public/img/upyun_logo.svg","hash":"1f118b2b9c54f431d5e731ccf316ceefe605ba67","modified":1562783112126},{"_id":"public/fonts/MaterialIcons-Regular.woff","hash":"c6c953c2ccb2ca9abb21db8dbf473b5a435f0082","modified":1562783112126},{"_id":"public/fonts/MaterialIcons-Regular.woff2","hash":"09963592e8c953cc7e14e3fb0a5b05d5042e8435","modified":1562783112126},{"_id":"public/img/footer/footer_ico-bilibili.svg","hash":"1a007ae30d69aa597f589edb4ee0638a9814c988","modified":1562783112126},{"_id":"public/img/footer/footer_ico-facebook.svg","hash":"74b3b3c6bd1d76b7eaaf75d36ac929b11a5a3e82","modified":1562783112126},{"_id":"public/img/footer/footer_ico-github.svg","hash":"5f1f9f53e6a87ad674108c6bd16e424a1e888c61","modified":1562783112126},{"_id":"public/img/footer/footer_ico-instagram.svg","hash":"294c511e62063ea49f61e23958ab27d643ba0228","modified":1562783112126},{"_id":"public/img/footer/footer_ico-linkedin.svg","hash":"9831c86352ec5ff283a3277d033120f86388c277","modified":1562783112127},{"_id":"public/img/footer/footer_ico-telegram.svg","hash":"413d66e40ca476deeb49364935d49d2f7839cdfd","modified":1562783112127},{"_id":"public/img/footer/footer_ico-tumblr.svg","hash":"11daf4fa4220787306fc21a879429e98b7db8d03","modified":1562783112127},{"_id":"public/img/footer/footer_ico-v2ex.svg","hash":"c5ffaf67a97e534c266d1585a9a3b56f1bfe3052","modified":1562783112127},{"_id":"public/img/footer/footer_ico-weibo.svg","hash":"26d0cdb77f0c4afd60111176167eacfa222bc4c1","modified":1562783112127},{"_id":"public/img/footer/footer_ico-zhihu.svg","hash":"d3f8da320fffefc5144822665dfe17d25af4061c","modified":1562783112127},{"_id":"public/img/gallery/arrow.svg","hash":"144d73877e52acc5068bc0c9d1e69ef450e69f26","modified":1562783112127},{"_id":"public/img/gallery/close.svg","hash":"2690088060811f01c9360df75be80070156ff176","modified":1562783112127},{"_id":"public/img/gallery/spinner.svg","hash":"fc9d1cd1118ac896d4f5326e110a653f3ea32b11","modified":1562783112127},{"_id":"public/img/random/material-10.png","hash":"363466a376e4df9e61acc904cd25f3c7ae1a7280","modified":1562783112128},{"_id":"public/img/random/material-12.png","hash":"d020b3d42542715c7ae95b3d8603fe3180bfe8f3","modified":1562783112128},{"_id":"public/img/footer/footer_ico-gplus.svg","hash":"b50274133ab263bcacdf729871d0446b615ac984","modified":1562783112128},{"_id":"public/img/footer/footer_ico-twitter.svg","hash":"58df7777d6fcee8fa3c42453c091714bb3f97c95","modified":1562783112128},{"_id":"public/img/random/material-19.png","hash":"768ed1a4966e2e418cb00f6b36d2fc9058328eb3","modified":1562783112128},{"_id":"public/img/random/material-17.png","hash":"ece82810e31f711576db598c845c3d97bd49fe67","modified":1562783112128},{"_id":"public/img/random/material-3.png","hash":"848eaa70b9b0cd7a2204c78e8aa324d8f96bb097","modified":1562783112128},{"_id":"public/img/random/material-8.png","hash":"57db542d526ef6866cb34e261096e93a0e6f3a82","modified":1562783112128},{"_id":"public/img/random/material-6.png","hash":"2f841e0c064fecb607ad1e149662a0c96d9e725d","modified":1562783112129},{"_id":"public/img/random/material-9.png","hash":"840319c4d1f38fb8df79eb4669ed2e14d89fd680","modified":1562783112129},{"_id":"public/img/random/material-4.png","hash":"b475dfbf67a076a4e17a5527fd1973b1d4adac07","modified":1562783112129},{"_id":"public/2018/05/03/svm从原理到实现/svm_model.gif","hash":"dd200e24bdcb73703b70d3448c6bbcfa796f956c","modified":1562783112129},{"_id":"public/2018/05/03/svm从原理到实现/svm_model.png","hash":"26a4914014238720238426dbfb0acb2397540bd5","modified":1562783112129},{"_id":"public/2018/05/03/svm从原理到实现/index.html","hash":"b7e85047b994e1b75748ad806f843f471d8b3c9a","modified":1562783185286},{"_id":"public/2018/05/03/让机器读懂文章-pLSA模型推导及实现/index.html","hash":"49001ad8659d175f94b907b8fc4d288391374ad9","modified":1562783255418},{"_id":"public/index.html","hash":"bfa66cfda1cdf7e7bb117dbaccbba884ac681b87","modified":1562783185287},{"_id":"public/tags/算法/index.html","hash":"c3a75f194049f7dd6a71bc6366b235063099f2c9","modified":1562783185287},{"_id":"public/tags/机器学习/index.html","hash":"b5b71086ad0d6086025b3cd2dcc2d290236f4e9a","modified":1562783185287},{"_id":"public/archives/index.html","hash":"6e27877b9a29d828359410568c3416c083a5f0fd","modified":1562783185287},{"_id":"public/archives/2018/index.html","hash":"560f51e4babc515caae27205576ea03699791765","modified":1562783185287},{"_id":"public/archives/2018/05/index.html","hash":"d711c2b38f677ccbff58d786914a4bb52b148e09","modified":1562783185287},{"_id":"public/categories/机器学习/index.html","hash":"09e4b9f13e8c736328b815f6e0d06b75bf479a30","modified":1562783185286},{"_id":"public/categories/机器学习/算法/index.html","hash":"d17102b7e66b2c8b2f79374ed1b8ea02fb1e49f1","modified":1562783185286},{"_id":"public/img/daily_pic.png","hash":"5e9a5f6a134889d0242e69061837f2032416d7ce","modified":1562783112143},{"_id":"public/fonts/MaterialIcons-Regular.ttf","hash":"fc05de31234e0090f7ddc28ce1b23af4026cb1da","modified":1562783112144},{"_id":"public/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1562783112144},{"_id":"public/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1562783112144},{"_id":"public/img/random/material-1.png","hash":"4839299eaa4db7272befa7b824e54b647fbbfc44","modified":1562783112145},{"_id":"public/img/random/material-13.png","hash":"1a8378db3121b583485e2b939cb1aa0e0b14b0c8","modified":1562783112145},{"_id":"public/img/random/material-14.png","hash":"b4f65b601960138c69f57171b0ddd55895483f45","modified":1562783112146},{"_id":"public/img/random/material-11.png","hash":"ce20b0ad08a248c036115374f2edb7301ff60b72","modified":1562783112146},{"_id":"public/img/random/material-15.png","hash":"36b9937cf3810e4970902b78797ad29b0831f065","modified":1562783112146},{"_id":"public/img/random/material-16.png","hash":"ade7f75200d3fb38326e3cf1e9f1a812fb12a43b","modified":1562783112146},{"_id":"public/img/random/material-18.png","hash":"4b98204abe36ecd3f30678d2c22059130e0db328","modified":1562783112146},{"_id":"public/img/random/material-5.png","hash":"5041ebd073a139c67f8ed271e74c967c7eb9c5be","modified":1562783112146},{"_id":"public/img/random/material-7.png","hash":"5c49ff3c064aaeb21227c2bd98b5ae422ddca84c","modified":1562783112146},{"_id":"public/img/random/material-2.png","hash":"faba2ce69c19d6c1dac392dd10b054e0061f6fb7","modified":1562783112147},{"_id":"public/css/ie-blocker.css","hash":"dddce7e6250a449291888ae7865697282a213b14","modified":1562783112152},{"_id":"public/css/uc.css","hash":"1e0977a2c9bdf721cc05654dfc025dd250655852","modified":1562783112152},{"_id":"public/css/prettify.css","hash":"c395f20ee64e80c2b6b15c7dade02f9aaaeab2c8","modified":1562783112152},{"_id":"public/css/prettify.min.css","hash":"62edd8f08656463b0e077dcf893faa3cc8eb5fe4","modified":1562783112152},{"_id":"public/js/ie-blocker.en.js","hash":"96ca8e677a12048d099319ebdf01983ddc6ca80c","modified":1562783112152},{"_id":"public/js/hanabi-browser-bundle.js","hash":"d646647bda386140c8315d60e3ff4ddbdb15c1ea","modified":1562783112152},{"_id":"public/js/lazyload.min.js","hash":"5348fd7aa4dbefac9d21091c9fd5e263563b5540","modified":1562783112152},{"_id":"public/js/lsloader.min.js","hash":"1a68a8d267948ea8475245b7d365a1a1bd8f732e","modified":1562783112152},{"_id":"public/js/nprogress.js","hash":"a3058d4b6afb5d7a14e5afcbb88f778de35864f0","modified":1562783112152},{"_id":"public/js/queue.js","hash":"dd252616b568b71c222d9cfc859bfe52738e576a","modified":1562783112152},{"_id":"public/js/queue.min.js","hash":"21aab782ca33efbb1386cc960b6be0a02106760d","modified":1562783112152},{"_id":"public/js/smoothscroll.js","hash":"df56a1c84191a62750ae820943377b6775fca0e2","modified":1562783112153},{"_id":"public/js/ie-blocker.zhCN.js","hash":"0ed49b0ec1d1924b128fbd97fca2cf7af7856fdf","modified":1562783112153},{"_id":"public/css/prettify/atelier-cave-dark.min.css","hash":"cb0156cdc36500a26b232ae1c81fdc880eba85e7","modified":1562783112153},{"_id":"public/css/prettify/atelier-cave-light.min.css","hash":"4b62dc45aa351b071d6a434dc54fe8c2e15c85cc","modified":1562783112153},{"_id":"public/css/prettify/atelier-dune-dark.min.css","hash":"c5094d99ca0e619d97860c88211bf908fdf830b1","modified":1562783112153},{"_id":"public/css/prettify/atelier-dune-light.min.css","hash":"b3ad98483e4d5bde72d52a15423d98e0d086db09","modified":1562783112153},{"_id":"public/css/prettify/atelier-forest-light.min.css","hash":"3532f6e86bf4afbba05f7a074b791b73174f9622","modified":1562783112153},{"_id":"public/css/prettify/atelier-forest-dark.min.css","hash":"9296b851a5b66785a60afa5da5fe9080bda96bf5","modified":1562783112153},{"_id":"public/css/prettify/atelier-heath-dark.min.css","hash":"954309acd7918422382a3ff2f9c2988aec0ff956","modified":1562783112153},{"_id":"public/css/prettify/atelier-heath-light.min.css","hash":"a67199fa580b3aa2df031e5d2028929d29ca3b45","modified":1562783112153},{"_id":"public/css/prettify/atelier-lakeside-dark.min.css","hash":"18575fc6dff855e395a39d0383d2f18807091f0d","modified":1562783112153},{"_id":"public/css/prettify/atelier-savanna-dark.min.css","hash":"fba92c652fd6704422b8f2bbc11706805a6faed0","modified":1562783112153},{"_id":"public/css/prettify/atelier-plateau-light.min.css","hash":"153801640fdcbb74c0de3f15345110f2210eb991","modified":1562783112153},{"_id":"public/css/prettify/atelier-savanna-light.min.css","hash":"d9425ffb7c60d646190c22b9a5f72091ee5f9ace","modified":1562783112153},{"_id":"public/css/prettify/atelier-seaside-dark.min.css","hash":"e0e6bbacc75a349b1e49c236d374b0e42f1fd485","modified":1562783112154},{"_id":"public/css/prettify/atelier-seaside-light.min.css","hash":"732750b75389c1c49204f37705e6abeee40ce64f","modified":1562783112154},{"_id":"public/css/prettify/atelier-sulphurpool-light.min.css","hash":"ab1a6200eab648cab443c3df77fde9b237ef27b6","modified":1562783112154},{"_id":"public/css/prettify/atelier-estuary-light.min.css","hash":"1d12d8f7fa9c122a186ee76fdf681c191a68f104","modified":1562783112154},{"_id":"public/css/prettify/github.min.css","hash":"19cf828225288fa5c006f1d8f66c39d11f4ef7f2","modified":1562783112154},{"_id":"public/css/prettify/atelier-lakeside-light.min.css","hash":"e20e8ac64432fa1aa6f74792b58196af7cf79c12","modified":1562783112154},{"_id":"public/css/prettify/hemisu-light.min.css","hash":"b2556ff41e513fd13d032ec84a37ee260a905815","modified":1562783112154},{"_id":"public/css/prettify/tomorrow-night-blue.min.css","hash":"c442728d96485bcf816151fe6bd96993aae09852","modified":1562783112154},{"_id":"public/css/prettify/tomorrow-night-bright.min.css","hash":"cf251fd3edfd736695272a0f1b41d509b7bb1fb9","modified":1562783112154},{"_id":"public/css/prettify/tomorrow-night-eighties.min.css","hash":"6ce259d674bb4edda23eea32b2379be17d0e0e6e","modified":1562783112154},{"_id":"public/css/prettify/tomorrow-night.min.css","hash":"d989206d124035494acb4b0cdc7fbc89f3b7d108","modified":1562783112154},{"_id":"public/css/prettify/tranquil-heart.min.css","hash":"0f6eefbdda8e410832e9c516a5dd19899217ef06","modified":1562783112154},{"_id":"public/css/prettify/tomorrow.min.css","hash":"b2c6d610b77f0273fefab5aa4ad26a7f58956f87","modified":1562783112154},{"_id":"public/css/prettify/github-v2.min.css","hash":"57630621d20842a529bdea7b17fc90f520e562ef","modified":1562783112154},{"_id":"public/css/prettify/vibrant-ink.min.css","hash":"c265bac6c31cf622b536b29c8a6bc46955d6fe63","modified":1562783112154},{"_id":"public/css/prettify/hemisu-dark.min.css","hash":"a671248cfd573292026d2174817e82e593691052","modified":1562783112154},{"_id":"public/css/prettify/atelier-estuary-dark.min.css","hash":"7e3a065cafeb3acc1d7178f64ef4265f5d5ad2b9","modified":1562783112155},{"_id":"public/css/prettify/atelier-plateau-dark.min.css","hash":"137e3c499a720da3c1d57b4dc53264b1d623e1c5","modified":1562783112155},{"_id":"public/css/prettify/atelier-sulphurpool-dark.min.css","hash":"015a35dddaee153fa8bb71d7f3818a6ba4d120d8","modified":1562783112155},{"_id":"public/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1562783112155},{"_id":"public/fonts/MaterialIcons-Regular.eot","hash":"26fb8cecb5512223277b4d290a24492a0f09ede1","modified":1562783112155},{"_id":"public/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1562783112155},{"_id":"public/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1562783112156},{"_id":"public/css/disqus-proxy.min.css","hash":"3f8f99f71d361302288b0ba11fd36072564b08c2","modified":1562783112165},{"_id":"public/css/duoshuo.min.css","hash":"89a30544b8b01d061da51c40f2af702a7969de5e","modified":1562783112165},{"_id":"public/css/duoshuo.css","hash":"32a02eaa01ff7b66fd9df307b0d33d52810096be","modified":1562783112165},{"_id":"public/js/lsloader.js","hash":"2b14e57784fb6b5f58d71584189c61af45f393e8","modified":1562783112165},{"_id":"public/js/prettify.min.js","hash":"69908fe0a09cee107c25cb5d769b861723e7b7bb","modified":1562783112165},{"_id":"public/css/disqus-proxy.css","hash":"d5086cda8aaae20b8d3f9dd50f0be5ccb717e42a","modified":1562783112167},{"_id":"public/js/Valine.min.js","hash":"6a287a99a772a0ea8f98b133523429c9250cc67f","modified":1562783112167},{"_id":"public/img/avatar.jpg","hash":"ad463ca55f48284e30c654c49d0e64beac6ca004","modified":1562783112167},{"_id":"public/css/fontawesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1562783112168},{"_id":"public/css/gallery.min.css","hash":"c5333ca835aae49239d809130a7b281af745729e","modified":1562783112168},{"_id":"public/js/gallery/gallery.js","hash":"8ee48312a183b42a9886211a0ec825ea0d041301","modified":1562783112168},{"_id":"public/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1562783112196},{"_id":"public/fonts/Roboto-Black.ttf","hash":"0244e6497a51fb8a38ca7e6fe297b066e2e09af5","modified":1562783112213},{"_id":"public/fonts/Roboto-Light.ttf","hash":"b9ea2eaf26ff8fdcb5aee3e0c2c7a6084ebb6aac","modified":1562783112215},{"_id":"public/fonts/Roboto-Medium.ttf","hash":"3965419aab480c184f66bc5e39c1719a373a4ef6","modified":1562783112215},{"_id":"public/fonts/Roboto-Regular.ttf","hash":"06691e103d4d3ce1f1108d9b7d21254b714a41f8","modified":1562783112216},{"_id":"public/fonts/Roboto-Thin.ttf","hash":"ed5101c3a800f35e925603a406e0c2dc5278b96c","modified":1562783112216},{"_id":"public/fonts/Roboto-Bold.ttf","hash":"d1864343b543978bd491d40c80010cea50c1b7bf","modified":1562783112217},{"_id":"public/js/MathJax.js","hash":"a21703b5848325a902c9b39bbf3ca6490d3e1b1b","modified":1562783112298},{"_id":"public/css/material-icons.css","hash":"f6f95fe5190f3c65931847246621fb83754eb00c","modified":1562783112299},{"_id":"public/css/style.min.css","hash":"04f492093ea96e176438510c38d28f5450ebc7de","modified":1562783112350},{"_id":"public/css/material.min.css","hash":"1a19febb9214ab689b02f5bb8ccb23579e6c1181","modified":1562783112384},{"_id":"public/js/jquery.min.js","hash":"00073d6597d2760b81387274a9ec56b9d5cb1552","modified":1562783112415},{"_id":"public/css/style.css","hash":"02ea82d87b95d6d89472624e9c23be551289a1d3","modified":1562783112416},{"_id":"public/js/js.min.js","hash":"709d347d3be033b841de0493b7cf532b594bb1f6","modified":1562783112437},{"_id":"public/css/material.css","hash":"068e2b00f686157b6e8b78b9b808112adbedf4de","modified":1562783112437},{"_id":"public/js/js.js","hash":"64b3f20e7138674ecf21e6e3982565ea63feae26","modified":1562783112469},{"_id":"public/categories/自然语言处理/index.html","hash":"a83cc10c30e79fde5e523a0780b0f8b17dafef0f","modified":1562783185288},{"_id":"public/tags/自然语言处理/index.html","hash":"600e31c48a2c1cbb76c737bd246bb5283610e4f1","modified":1562783185288}],"Category":[{"name":"机器学习","_id":"cjxxkpq9k0001lutmomb1pl6g"},{"name":"算法","parent":"cjxxkpq9k0001lutmomb1pl6g","_id":"cjxxkpqap0005lutmi7hc4vfz"},{"name":"自然语言处理","_id":"cjxxkqxrs0002mvtmxuzkmkbu"}],"Data":[],"Page":[],"Post":[{"title":"svm从原理到实现","date":"2018-05-03T07:40:40.000Z","mathjax":true,"_content":"\n> **引言**：svm是一种二分类算法，它通过寻找特征空间中的一个超平面，将样本划分开来，通过一定的策略选择最优的超平面，以期获得较好的准确性能和泛化性能。\n\n<!-- more -->\n\n## 一、svm的模型\n在分类问题中，有一种思路是**在样本空间中寻找一个超平面将不同类的样本划分开**，依据此超平面，在新数据到来时，我们只需要看这个新的数据点落在超平面的哪一侧即可知道该数据的类别。\n![](svm_model.gif)\n用数学可以形式化地将这个超平面表示为\n\n$$\nw^Tx+b=0\n$$\n\n\n如果给定一个训练样本\n$$\n(X_0, y_0)\n$$\n但问题是能够将样本划分开的超平面可能不止一个，那我们要如何选择最好的超平面呢？从数学的角度来讲，我们该如何\n\n$$\n\\begin{eqnarray}\n\\nabla\\cdot\\vec{E} &=& \\frac{\\rho}{\\epsilon_0} \\\\\n\\nabla\\cdot\\vec{B} &=& 0 \\\\\n\\nabla\\times\\vec{E} &=& -\\frac{\\partial B}{\\partial t} \\\\\n\\nabla\\times\\vec{B} &=& \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)\n\\end{eqnarray}\n$$\n## 二、svm的策略\n\n## 三、svm的数学推导\n## 四、svm的算法\n","source":"_posts/svm从原理到实现.md","raw":"---\ntitle: svm从原理到实现\ndate: 2018-05-03 15:40:40\ntags: [算法, 机器学习]\nmathjax: true\ncategories:\n    - 机器学习\n    - 算法\n---\n\n> **引言**：svm是一种二分类算法，它通过寻找特征空间中的一个超平面，将样本划分开来，通过一定的策略选择最优的超平面，以期获得较好的准确性能和泛化性能。\n\n<!-- more -->\n\n## 一、svm的模型\n在分类问题中，有一种思路是**在样本空间中寻找一个超平面将不同类的样本划分开**，依据此超平面，在新数据到来时，我们只需要看这个新的数据点落在超平面的哪一侧即可知道该数据的类别。\n![](svm_model.gif)\n用数学可以形式化地将这个超平面表示为\n\n$$\nw^Tx+b=0\n$$\n\n\n如果给定一个训练样本\n$$\n(X_0, y_0)\n$$\n但问题是能够将样本划分开的超平面可能不止一个，那我们要如何选择最好的超平面呢？从数学的角度来讲，我们该如何\n\n$$\n\\begin{eqnarray}\n\\nabla\\cdot\\vec{E} &=& \\frac{\\rho}{\\epsilon_0} \\\\\n\\nabla\\cdot\\vec{B} &=& 0 \\\\\n\\nabla\\times\\vec{E} &=& -\\frac{\\partial B}{\\partial t} \\\\\n\\nabla\\times\\vec{B} &=& \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)\n\\end{eqnarray}\n$$\n## 二、svm的策略\n\n## 三、svm的数学推导\n## 四、svm的算法\n","slug":"svm从原理到实现","published":1,"updated":"2019-07-10T16:59:42.080Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxxkpq8a0000lutmu63nbpqh","content":"<blockquote>\n<p><strong>引言</strong>：svm是一种二分类算法，它通过寻找特征空间中的一个超平面，将样本划分开来，通过一定的策略选择最优的超平面，以期获得较好的准确性能和泛化性能。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"一、svm的模型\"><a href=\"#一、svm的模型\" class=\"headerlink\" title=\"一、svm的模型\"></a>一、svm的模型</h2><p>在分类问题中，有一种思路是<strong>在样本空间中寻找一个超平面将不同类的样本划分开</strong>，依据此超平面，在新数据到来时，我们只需要看这个新的数据点落在超平面的哪一侧即可知道该数据的类别。<br><img src=\"svm_model.gif\" alt><br>用数学可以形式化地将这个超平面表示为</p>\n<script type=\"math/tex; mode=display\">\nw^Tx+b=0</script><p>如果给定一个训练样本</p>\n<script type=\"math/tex; mode=display\">\n(X_0, y_0)</script><p>但问题是能够将样本划分开的超平面可能不止一个，那我们要如何选择最好的超平面呢？从数学的角度来讲，我们该如何</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray}\n\\nabla\\cdot\\vec{E} &=& \\frac{\\rho}{\\epsilon_0} \\\\\n\\nabla\\cdot\\vec{B} &=& 0 \\\\\n\\nabla\\times\\vec{E} &=& -\\frac{\\partial B}{\\partial t} \\\\\n\\nabla\\times\\vec{B} &=& \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)\n\\end{eqnarray}</script><h2 id=\"二、svm的策略\"><a href=\"#二、svm的策略\" class=\"headerlink\" title=\"二、svm的策略\"></a>二、svm的策略</h2><h2 id=\"三、svm的数学推导\"><a href=\"#三、svm的数学推导\" class=\"headerlink\" title=\"三、svm的数学推导\"></a>三、svm的数学推导</h2><h2 id=\"四、svm的算法\"><a href=\"#四、svm的算法\" class=\"headerlink\" title=\"四、svm的算法\"></a>四、svm的算法</h2>","site":{"data":{}},"excerpt":"<blockquote>\n<p><strong>引言</strong>：svm是一种二分类算法，它通过寻找特征空间中的一个超平面，将样本划分开来，通过一定的策略选择最优的超平面，以期获得较好的准确性能和泛化性能。</p>\n</blockquote>","more":"<h2 id=\"一、svm的模型\"><a href=\"#一、svm的模型\" class=\"headerlink\" title=\"一、svm的模型\"></a>一、svm的模型</h2><p>在分类问题中，有一种思路是<strong>在样本空间中寻找一个超平面将不同类的样本划分开</strong>，依据此超平面，在新数据到来时，我们只需要看这个新的数据点落在超平面的哪一侧即可知道该数据的类别。<br><img src=\"svm_model.gif\" alt><br>用数学可以形式化地将这个超平面表示为</p>\n<script type=\"math/tex; mode=display\">\nw^Tx+b=0</script><p>如果给定一个训练样本</p>\n<script type=\"math/tex; mode=display\">\n(X_0, y_0)</script><p>但问题是能够将样本划分开的超平面可能不止一个，那我们要如何选择最好的超平面呢？从数学的角度来讲，我们该如何</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray}\n\\nabla\\cdot\\vec{E} &=& \\frac{\\rho}{\\epsilon_0} \\\\\n\\nabla\\cdot\\vec{B} &=& 0 \\\\\n\\nabla\\times\\vec{E} &=& -\\frac{\\partial B}{\\partial t} \\\\\n\\nabla\\times\\vec{B} &=& \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)\n\\end{eqnarray}</script><h2 id=\"二、svm的策略\"><a href=\"#二、svm的策略\" class=\"headerlink\" title=\"二、svm的策略\"></a>二、svm的策略</h2><h2 id=\"三、svm的数学推导\"><a href=\"#三、svm的数学推导\" class=\"headerlink\" title=\"三、svm的数学推导\"></a>三、svm的数学推导</h2><h2 id=\"四、svm的算法\"><a href=\"#四、svm的算法\" class=\"headerlink\" title=\"四、svm的算法\"></a>四、svm的算法</h2>"},{"title":"让机器读懂文章-pLSA模型推导及实现","date":"2018-05-03T07:40:40.000Z","mathjax":true,"_content":"\n## 概述\n人类读懂文章是一个很自然的行为，当我们读完一篇《背影》的时候，我们就可以知道这篇文章在写些什么，也就是我们说获得了这篇文章的相关知识。有了这些知识，我们就可以回答一些问题，例如:\n\n1. 问：这篇文章写的主要内容是什么呢？\n    答： 亲情、送别\n2. 问：有类似《背影》这样的文章可以推荐的吗？\n    答：龙应台-《送别》\n\n虽然上面的问答对任务对人类来说十分简单，但对于机器来说却并不容易。机器对自然语言(中文文本)的理解实际上并不是非常简单的事情，因为自然语言本身是一个高层抽象的概念，而机器只擅长处理量化的知识，例如说让机器记住向量$\\vec x=[1, 2, 3]$和$\\vec y=[4, 5, 6]$是十分容易的事情，而且可以轻易知道$\\vec x$和$\\vec y$的相似程度，这只需要计算其记录即可，于是我们对于向量来说就可以完成上面的问题2了。\n\n让我们重新揣摩一下人类读懂文章的过程，实际上我们并不需要背熟每一个字词，而是阅读完成之后再总结出这篇文章主要在写什么，也就是文章的主题。为了让机器能理解文章，我们也需要把这些主题量化出来，形成类似$\\overrightarrow {topic}=['亲情': 0.5, '送别': 0.5]$的向量，这种能量化文章主题的模型，也就叫做**主题模型**了。\n\n在主题模型方面前人们已经做了很多工作，并且取得了非常不错的成效，其中影响较大的是一类模型叫做**隐语义模型**，而这类模型里面**概率隐语义分析**也就是本文所述的pLSA则是应用最成功的模型之一，同样成功的模型还有**隐含狄利克雷分布**，也就是大名鼎鼎的LDA主题模型，不过LDA与pLSA的思想一脉相承，只不过做了贝叶斯改造而已。\n\n\n## pLSA模型\n\n事实上pLSA是在对我们写一篇文章的行为建模，我们先揣摩朱自清先生写《背影》的行为。首先我朱先生敲定了今天要写一篇《背影》，然后他开始构思了这篇文章的主题为：亲情、送别，并且朱先生认为这两部分的内容都几乎同等重要，也就是: $['亲情': 0.5, '送别': 0.5]$，朱先生开始动笔，于是当朱先生写下\n\n> 我买几个橘子去，你就在此地，不要走动。\n\n实际上是朱先生先前构思好的亲情、父子、送别这三个中心思想在影响着朱先生写下了这段话。于是在这三个中心思想的影响下，朱先生写完了《背影》里面的所有词，而我们读者所谓的**理解**《背影》，实际上就是从我们看到的《背影》的所有词，推断出了朱先生构思的主题: $['亲情': 0.5, '送别': 0.5]$。而pLSA则只是用数学化的形式描述这个过程, 这样一个形式化的过程在pLSA的眼里是这样的：\n\n1.  从分布$p(d_m)$上采样选择了一篇文章$d_m$\n2. 对于文章$d_m$每一个词，从分布$p(z_k|d_m)$上采样一个生成一个主题$z_k$\n3. 从分布$p(w_n|z_k)$上采样生成了一个词$w_n$\n\n这个模型可以用plate notation更加简洁地描述：\n\n![pLSA模型](https://img-blog.csdnimg.cn/20181230011214553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTMyOTgzMDA=,size_16,color_FFFFFF,t_70#pic_center)\n图中的阴影部分的变量$d$和$w$对应着文章和文章的所有词，表示可观测的变量，$z$是观测不到的主题，我们称之为隐变量，两个框框左下角的$N$和$M$则分别表示$N$和$M$词独立重复试验。这个图所表达的文章生成过程跟上面的文字表述是一致的。\n\n这样写文章的模型是符合直觉的，但仔细推敲总觉得过于机械生硬，这样的机械式过程能写得出朱先生《背影》那样优秀的文章吗? \n> 如果无限多个猴子任意敲打打字机键，最终会写出大英博物馆的所有藏书 -- 爱丁顿无限猴子理论\n\n一件小概率的事件在多次试验中必然发生，这就是为什么随机敲打键盘的猴子也能作的原因，于是上面问题答案自然是肯定的，pLSA这样合乎直觉的模型当然要比一只茫无目的敲打键盘的猴子更加具备写作天赋。\n\n我们读者需要阅读根据文章和文章的所有内容去推断文章的主题，而pLSA眼里则是根据可观测变量$w$和可观测变量$d$去推断隐变量$z$。我们可以通过海量的文章去解算出模型中的参数，也就是上文中的$p(z_k|p_m)$和$p(w_n|z_k)$两个分布，我们称之为**文章主题分布**和**主题词分布**。 而$p(z_k|d_m)$这个分布实际上就是文章$d_m$的主题分布，也就是我们前文所说的$['亲情': 0.5, '送别': 0.5]$这样的文章主题，这个分布就是我们就获取到关于文章的知识，它量化说明了文章$d_m$在说什么内容。至于模型参数解算的过程，这没什么不可以理解的，正如我定义了一个$y$的产生过程过$y=ax+b$, 当我拿到足够多的样本$y_0=0, y_1=1, y_2=2,....y_n=n$之后，实际上我可以将他们组成方程组解出合理的参数$a$、$b$和$x$来。\n\n行文至此，我们且对pLSA的求解按下不表，先来实际感受一下pLSA的作用。这里选择格林童话中的十几篇童话作为语料训练pLSA，然后分别从5个主题分布中取出的top3词语：\n\n| topic-1 |  topic-2 | topic-3 | topic-4 | topic-5 |\n|--|--|--|--|--|\n| wrong |  birds | morning | soldier | good |\n| issue |  fox | met | king | gave |\n| faith |  horse | wood | castle | great |\n\n可以看到pLSA是可以正确推导出来主题分布的。\n\n## pLSA的EM算法推导\n\npLSA是一种含隐变量的生成模型，也就是概率化地描述了样本数据(文章)的生成并且包含隐藏变量的模型，对于这种模型可用MCMC或EM算法来求解。本文讲解的是pLSA的EM算法求解，这里并不打算讲解EM的具体推导，而是直接利用EM算法的结论来对pLSA模型求解，关于EM算法的内容读者可以自己网上搜罗一下资料，或者待我抽空再写一篇关于EM算法的文章。\n在开始推导之前，我们先假设词库大小为$j$, 每篇文章都由词库中的词$w_j$构成。然后定义模型参数:\n$$\n\\begin{aligned}\n\\theta_{mk}=p(z_k|d_m) \\\\\n\\psi_{kj} = p(w_j|z_k)\n\\end{aligned} \\tag{1}\n$$\n根据EM算法的求解步骤，我们先根据plate notation写出联合分布:\n$$\n\tp(\\bf w, \\bf z, \\bf d) = \\prod_m p(d_m) \\prod_n p(w_{mn}|z_{mn})p(z_{mn}|d_m) \\tag{2}\n$$\n其中$d_m$表示第$m$篇文章， $w_{mn}$表示第$m$篇文章中的第$n$个词，$z_{mn}$表示第$m$篇文章中第$n$个词对应的主题。然后我们令给定模型参数下的主题后验证分布为：\n$$\n\tQ(\\bf z; \\bf \\theta, \\bf \\psi) = p(\\bf z|\\bf d, \\bf w; \\bf \\theta, \\bf \\psi) \\tag{3}\n$$\n于是可以启动EM算法当中的求期望步骤：\n$$\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)] \\tag{4}\n$$\n其中$q(z_{mnk})$表示在给定参数下的主题验分布，这里有:\n$$\nq(z_{mnk}) = p(z_k|d_m, w_n; \\theta_{mk}, \\psi_{kj}) = \\frac {p(d_m)\\theta_{mk}\\psi_{kn}}{\\sum_kp(d_m)\\theta_{mk}\\psi_{kn}} \\tag{5}\n$$\n\n由于文章中总会出现许多重复词，例如文章$d_m$中第1个词和第$5$个词是一样的，那么就会有$w_{m1}=w_{m5}=w_j$那么对于式子$(4)$中$\\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)]$这部分，我们可以将文章$d_m$中重复出现的词对应的项合并成为$\\sum_j n_{mj}\\sum_kq(z_{mjk})ln[p(w_j|z_k)p(z_k|d_m)]$, 其中$n_{mj}$为文章$d_m$中词$w_j$出现的次数。于是我们重写式子$(4)$为：\n$$\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\tag{6}\n$$\n我们的目标是最大化式子$(6)$, 并且因为参数$\\bf \\theta$和$\\bf \\psi$是概率分布，所以有要约束$\\sum_k\\theta_{km}=1$和$\\sum_j{\\psi_{kj}} = 1$, 并且由于$p(d_m)$这个先验证分布可以设置为常数，这样我们去除与优化无关的常数项和增加了约束之后，就可以得到整个带约束的优化目标:\n\n$$\n\\begin{aligned}\n\t\\max \\limits_{\\theta_{mk}, \\psi_{kj}}   \\quad & \\sum_m \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\\\\n\t\\bf{s.t.} \\quad & \\sum_{k}\\theta_{mk}=1, m=1,2,3,...,M \\\\\n\t& \\sum_{j} \\psi_{kj} = 1, k=1,2,3,...,K\n\\end{aligned} \\tag{7}\n$$\n\n这个带约束的优化目标直接使用拉格朗日乘子法：\n$$\n\tL(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha) = \\sum_m \\sum_j n_{mj} \\sum_k  q(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) + \\sum_m {\\lambda_m} (1-\\sum_k\\theta_{mk}) + \\sum_k \\alpha_{k} (1-\\sum_j {\\psi_{kj}}) \\tag{8}\n$$\n于是可以对参数$\\theta_{mk}$求导并令其为0:\n$$\n\\frac{ \\partial L(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha)}{\\partial \\theta_{mk}} = \\frac{ \\sum_jn_{mj}q(z_{mjk})}{\\theta_{mk}} - \\lambda_m = 0 \\\\\n \\lambda_m \\theta_{mk} ={ \\sum_jn_{mj}q(z_{mjk})}  \\tag{9}\n$$\n式子(9)左右两边对$k$求和得到:\n$$\n\\lambda_m \\sum_k \\theta_{mk} = \\sum_j{n_{mj}} \\sum_{z}q(z_{mjk}) \\\\\n\\lambda_m = \\sum_j {n_{mj}} = N_m \\tag{10}\n$$\n上述式子(10)中$N_m$表示文章$d_m$的总词数，将式子$(10)$代回式(9)可以得到:\n$$\n\\theta_{mk} = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\tag{11}\n$$\n同样地我们对参数$\\psi_{kj}$故技重施:\n$$\n\\frac {\\partial L(\\bf \\theta, \\bf \\psi,\\bf \\lambda, \\bf \\alpha)}{\\partial \\psi_{kj}} = \\frac{\\sum_m n_{mj}q(z_{mjk})}{\\psi_{kj}} - \\alpha_k = 0 \\\\\n\\alpha_k \\psi_{kj} = \\sum_m n_{mj}q(z_{mjk}) \\tag{12}\n$$\n式子(12)左右两边对$j$求和得到:\n$$\n\\alpha_k \\sum_{j} \\psi_{kj} = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\\\\n\\alpha_k = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\tag{13}\n$$\n将式子代回$(12)$得到：\n$$\n\\psi_{kj} = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})} \\tag{14}\n$$\n至此，pLSA参数求解完毕。根据参数更新的规则，我们设在EM算法迭代运行的过程中，第$i$轮的参数为$\\theta_{mk}^i$和$\\psi_{kj}^i$。于是整个pLSA的EM算法可以归纳为：\n\n1.  随机初始化参数$\\theta_{mk}^0$和$\\psi_{kj}^0$\n2. 开始第$i\\in[1, 2, 3...n]$轮迭代:\n\ta. 求$q(z_{mjk})=\\frac {p(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}{\\sum_kp(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}$\n\tb. 更新参数\n\t$$\n\t\t\\theta_{mk}^i = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\\\\n\t\t\\psi_{kj}^i = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})}\n\t$$\n\tc. 若参数收敛，则退出迭代，否则返回`a`继续迭代\n3. 输出模型参数$\\bf \\theta$和$\\bf \\psi$\n\n## pLSA的实现\n从上边的式子来看pLSA是相对比较容易实现的，但是高效地实现还需要一些技巧。首先看式(14)的分母，存在一个二阶求和的过程，如果语料库中有`1000`篇文档，`10000`个词，那么就要进行一千万次运算，这样显然必须要用并行批量计算的方式来加速，在实现上我们会将涉及的所有运算都转换为矩阵运算，这样就可以通过成熟的GPU库来加速运算。其次再看内存消耗问题，$q(z_{mjk})$总共需要储存`m*j*k`个参数，如果有`1000`篇文档`10000`个词和`50`个主题，那么$q(z_{mjk})$将有`5亿`个元素，这在内存消耗上是不可接受的，在实现上我们只会在批量计算$\\theta_{mk}$和$\\psi_{kj}$参数时用到的部分$q(z_{mjk})$批量计算出来，并且一旦使用完毕立即丢弃。具体代码就不在这里贴了，完整的demo见[pLSA实现](https://github.com/EmbolismSoil/pLSA)\n\n## 总结\npLSA是概率隐语义主题模型中相对简单的一种，推导和实现都相对简单，回头看上面的算法过程，实际上只需要简单地计数迭代而已，所以pLSA非常适合在线学习。其实并非pLSA有此特点，事实上大多数生成模型都一样适合在线学习。不过pLSA的缺点也是非常明显的，**pLSA将文章建模时没有考虑文章词序**，也就是我们随机将一篇文章词打散，对于pLSA来说，其联合概率$p(\\bf w, \\bf z, \\bf d)$是不变的,这一点回头看式子$(2)$就知道。这意味着\"谁是你爸爸\"和\"你爸爸是谁\"这两句话在pLSA眼里看来是一样的，这种情况在短文本场景中尤其常见。但幸运的是，在长文本领域，*有研表究明，汉字的序顺并不能影阅响读*。不过pLSA近年来正在逐渐被更新颖复杂的LDA代替，但相对LDA来说pLSA结构简单，容易做大规模并行化，所以时至今日，pLSA在大规模文本挖掘领域依旧光耀夺目。\n\n最后，向Thomas Hofmann先生致敬，感谢先生为我们带来如此精妙的pLSA主题模型。\n\n## 参考文献\n[1] [ Probabilistic Latent Semantic Analysis](https://arxiv.org/pdf/1301.6705.pdf)\n[2] [Tutorial on Probablistic Latent Semantic Analysis](https://arxiv.org/pdf/1212.3900.pdf)","source":"_posts/让机器读懂文章-pLSA模型推导及实现.md","raw":"---\ntitle: 让机器读懂文章-pLSA模型推导及实现\ndate: 2018-05-03 15:40:40\ntags: [自然语言处理]\nmathjax: true\ncategories:\n    - 自然语言处理\n---\n\n## 概述\n人类读懂文章是一个很自然的行为，当我们读完一篇《背影》的时候，我们就可以知道这篇文章在写些什么，也就是我们说获得了这篇文章的相关知识。有了这些知识，我们就可以回答一些问题，例如:\n\n1. 问：这篇文章写的主要内容是什么呢？\n    答： 亲情、送别\n2. 问：有类似《背影》这样的文章可以推荐的吗？\n    答：龙应台-《送别》\n\n虽然上面的问答对任务对人类来说十分简单，但对于机器来说却并不容易。机器对自然语言(中文文本)的理解实际上并不是非常简单的事情，因为自然语言本身是一个高层抽象的概念，而机器只擅长处理量化的知识，例如说让机器记住向量$\\vec x=[1, 2, 3]$和$\\vec y=[4, 5, 6]$是十分容易的事情，而且可以轻易知道$\\vec x$和$\\vec y$的相似程度，这只需要计算其记录即可，于是我们对于向量来说就可以完成上面的问题2了。\n\n让我们重新揣摩一下人类读懂文章的过程，实际上我们并不需要背熟每一个字词，而是阅读完成之后再总结出这篇文章主要在写什么，也就是文章的主题。为了让机器能理解文章，我们也需要把这些主题量化出来，形成类似$\\overrightarrow {topic}=['亲情': 0.5, '送别': 0.5]$的向量，这种能量化文章主题的模型，也就叫做**主题模型**了。\n\n在主题模型方面前人们已经做了很多工作，并且取得了非常不错的成效，其中影响较大的是一类模型叫做**隐语义模型**，而这类模型里面**概率隐语义分析**也就是本文所述的pLSA则是应用最成功的模型之一，同样成功的模型还有**隐含狄利克雷分布**，也就是大名鼎鼎的LDA主题模型，不过LDA与pLSA的思想一脉相承，只不过做了贝叶斯改造而已。\n\n\n## pLSA模型\n\n事实上pLSA是在对我们写一篇文章的行为建模，我们先揣摩朱自清先生写《背影》的行为。首先我朱先生敲定了今天要写一篇《背影》，然后他开始构思了这篇文章的主题为：亲情、送别，并且朱先生认为这两部分的内容都几乎同等重要，也就是: $['亲情': 0.5, '送别': 0.5]$，朱先生开始动笔，于是当朱先生写下\n\n> 我买几个橘子去，你就在此地，不要走动。\n\n实际上是朱先生先前构思好的亲情、父子、送别这三个中心思想在影响着朱先生写下了这段话。于是在这三个中心思想的影响下，朱先生写完了《背影》里面的所有词，而我们读者所谓的**理解**《背影》，实际上就是从我们看到的《背影》的所有词，推断出了朱先生构思的主题: $['亲情': 0.5, '送别': 0.5]$。而pLSA则只是用数学化的形式描述这个过程, 这样一个形式化的过程在pLSA的眼里是这样的：\n\n1.  从分布$p(d_m)$上采样选择了一篇文章$d_m$\n2. 对于文章$d_m$每一个词，从分布$p(z_k|d_m)$上采样一个生成一个主题$z_k$\n3. 从分布$p(w_n|z_k)$上采样生成了一个词$w_n$\n\n这个模型可以用plate notation更加简洁地描述：\n\n![pLSA模型](https://img-blog.csdnimg.cn/20181230011214553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTMyOTgzMDA=,size_16,color_FFFFFF,t_70#pic_center)\n图中的阴影部分的变量$d$和$w$对应着文章和文章的所有词，表示可观测的变量，$z$是观测不到的主题，我们称之为隐变量，两个框框左下角的$N$和$M$则分别表示$N$和$M$词独立重复试验。这个图所表达的文章生成过程跟上面的文字表述是一致的。\n\n这样写文章的模型是符合直觉的，但仔细推敲总觉得过于机械生硬，这样的机械式过程能写得出朱先生《背影》那样优秀的文章吗? \n> 如果无限多个猴子任意敲打打字机键，最终会写出大英博物馆的所有藏书 -- 爱丁顿无限猴子理论\n\n一件小概率的事件在多次试验中必然发生，这就是为什么随机敲打键盘的猴子也能作的原因，于是上面问题答案自然是肯定的，pLSA这样合乎直觉的模型当然要比一只茫无目的敲打键盘的猴子更加具备写作天赋。\n\n我们读者需要阅读根据文章和文章的所有内容去推断文章的主题，而pLSA眼里则是根据可观测变量$w$和可观测变量$d$去推断隐变量$z$。我们可以通过海量的文章去解算出模型中的参数，也就是上文中的$p(z_k|p_m)$和$p(w_n|z_k)$两个分布，我们称之为**文章主题分布**和**主题词分布**。 而$p(z_k|d_m)$这个分布实际上就是文章$d_m$的主题分布，也就是我们前文所说的$['亲情': 0.5, '送别': 0.5]$这样的文章主题，这个分布就是我们就获取到关于文章的知识，它量化说明了文章$d_m$在说什么内容。至于模型参数解算的过程，这没什么不可以理解的，正如我定义了一个$y$的产生过程过$y=ax+b$, 当我拿到足够多的样本$y_0=0, y_1=1, y_2=2,....y_n=n$之后，实际上我可以将他们组成方程组解出合理的参数$a$、$b$和$x$来。\n\n行文至此，我们且对pLSA的求解按下不表，先来实际感受一下pLSA的作用。这里选择格林童话中的十几篇童话作为语料训练pLSA，然后分别从5个主题分布中取出的top3词语：\n\n| topic-1 |  topic-2 | topic-3 | topic-4 | topic-5 |\n|--|--|--|--|--|\n| wrong |  birds | morning | soldier | good |\n| issue |  fox | met | king | gave |\n| faith |  horse | wood | castle | great |\n\n可以看到pLSA是可以正确推导出来主题分布的。\n\n## pLSA的EM算法推导\n\npLSA是一种含隐变量的生成模型，也就是概率化地描述了样本数据(文章)的生成并且包含隐藏变量的模型，对于这种模型可用MCMC或EM算法来求解。本文讲解的是pLSA的EM算法求解，这里并不打算讲解EM的具体推导，而是直接利用EM算法的结论来对pLSA模型求解，关于EM算法的内容读者可以自己网上搜罗一下资料，或者待我抽空再写一篇关于EM算法的文章。\n在开始推导之前，我们先假设词库大小为$j$, 每篇文章都由词库中的词$w_j$构成。然后定义模型参数:\n$$\n\\begin{aligned}\n\\theta_{mk}=p(z_k|d_m) \\\\\n\\psi_{kj} = p(w_j|z_k)\n\\end{aligned} \\tag{1}\n$$\n根据EM算法的求解步骤，我们先根据plate notation写出联合分布:\n$$\n\tp(\\bf w, \\bf z, \\bf d) = \\prod_m p(d_m) \\prod_n p(w_{mn}|z_{mn})p(z_{mn}|d_m) \\tag{2}\n$$\n其中$d_m$表示第$m$篇文章， $w_{mn}$表示第$m$篇文章中的第$n$个词，$z_{mn}$表示第$m$篇文章中第$n$个词对应的主题。然后我们令给定模型参数下的主题后验证分布为：\n$$\n\tQ(\\bf z; \\bf \\theta, \\bf \\psi) = p(\\bf z|\\bf d, \\bf w; \\bf \\theta, \\bf \\psi) \\tag{3}\n$$\n于是可以启动EM算法当中的求期望步骤：\n$$\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)] \\tag{4}\n$$\n其中$q(z_{mnk})$表示在给定参数下的主题验分布，这里有:\n$$\nq(z_{mnk}) = p(z_k|d_m, w_n; \\theta_{mk}, \\psi_{kj}) = \\frac {p(d_m)\\theta_{mk}\\psi_{kn}}{\\sum_kp(d_m)\\theta_{mk}\\psi_{kn}} \\tag{5}\n$$\n\n由于文章中总会出现许多重复词，例如文章$d_m$中第1个词和第$5$个词是一样的，那么就会有$w_{m1}=w_{m5}=w_j$那么对于式子$(4)$中$\\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)]$这部分，我们可以将文章$d_m$中重复出现的词对应的项合并成为$\\sum_j n_{mj}\\sum_kq(z_{mjk})ln[p(w_j|z_k)p(z_k|d_m)]$, 其中$n_{mj}$为文章$d_m$中词$w_j$出现的次数。于是我们重写式子$(4)$为：\n$$\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\tag{6}\n$$\n我们的目标是最大化式子$(6)$, 并且因为参数$\\bf \\theta$和$\\bf \\psi$是概率分布，所以有要约束$\\sum_k\\theta_{km}=1$和$\\sum_j{\\psi_{kj}} = 1$, 并且由于$p(d_m)$这个先验证分布可以设置为常数，这样我们去除与优化无关的常数项和增加了约束之后，就可以得到整个带约束的优化目标:\n\n$$\n\\begin{aligned}\n\t\\max \\limits_{\\theta_{mk}, \\psi_{kj}}   \\quad & \\sum_m \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\\\\n\t\\bf{s.t.} \\quad & \\sum_{k}\\theta_{mk}=1, m=1,2,3,...,M \\\\\n\t& \\sum_{j} \\psi_{kj} = 1, k=1,2,3,...,K\n\\end{aligned} \\tag{7}\n$$\n\n这个带约束的优化目标直接使用拉格朗日乘子法：\n$$\n\tL(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha) = \\sum_m \\sum_j n_{mj} \\sum_k  q(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) + \\sum_m {\\lambda_m} (1-\\sum_k\\theta_{mk}) + \\sum_k \\alpha_{k} (1-\\sum_j {\\psi_{kj}}) \\tag{8}\n$$\n于是可以对参数$\\theta_{mk}$求导并令其为0:\n$$\n\\frac{ \\partial L(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha)}{\\partial \\theta_{mk}} = \\frac{ \\sum_jn_{mj}q(z_{mjk})}{\\theta_{mk}} - \\lambda_m = 0 \\\\\n \\lambda_m \\theta_{mk} ={ \\sum_jn_{mj}q(z_{mjk})}  \\tag{9}\n$$\n式子(9)左右两边对$k$求和得到:\n$$\n\\lambda_m \\sum_k \\theta_{mk} = \\sum_j{n_{mj}} \\sum_{z}q(z_{mjk}) \\\\\n\\lambda_m = \\sum_j {n_{mj}} = N_m \\tag{10}\n$$\n上述式子(10)中$N_m$表示文章$d_m$的总词数，将式子$(10)$代回式(9)可以得到:\n$$\n\\theta_{mk} = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\tag{11}\n$$\n同样地我们对参数$\\psi_{kj}$故技重施:\n$$\n\\frac {\\partial L(\\bf \\theta, \\bf \\psi,\\bf \\lambda, \\bf \\alpha)}{\\partial \\psi_{kj}} = \\frac{\\sum_m n_{mj}q(z_{mjk})}{\\psi_{kj}} - \\alpha_k = 0 \\\\\n\\alpha_k \\psi_{kj} = \\sum_m n_{mj}q(z_{mjk}) \\tag{12}\n$$\n式子(12)左右两边对$j$求和得到:\n$$\n\\alpha_k \\sum_{j} \\psi_{kj} = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\\\\n\\alpha_k = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\tag{13}\n$$\n将式子代回$(12)$得到：\n$$\n\\psi_{kj} = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})} \\tag{14}\n$$\n至此，pLSA参数求解完毕。根据参数更新的规则，我们设在EM算法迭代运行的过程中，第$i$轮的参数为$\\theta_{mk}^i$和$\\psi_{kj}^i$。于是整个pLSA的EM算法可以归纳为：\n\n1.  随机初始化参数$\\theta_{mk}^0$和$\\psi_{kj}^0$\n2. 开始第$i\\in[1, 2, 3...n]$轮迭代:\n\ta. 求$q(z_{mjk})=\\frac {p(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}{\\sum_kp(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}$\n\tb. 更新参数\n\t$$\n\t\t\\theta_{mk}^i = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\\\\n\t\t\\psi_{kj}^i = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})}\n\t$$\n\tc. 若参数收敛，则退出迭代，否则返回`a`继续迭代\n3. 输出模型参数$\\bf \\theta$和$\\bf \\psi$\n\n## pLSA的实现\n从上边的式子来看pLSA是相对比较容易实现的，但是高效地实现还需要一些技巧。首先看式(14)的分母，存在一个二阶求和的过程，如果语料库中有`1000`篇文档，`10000`个词，那么就要进行一千万次运算，这样显然必须要用并行批量计算的方式来加速，在实现上我们会将涉及的所有运算都转换为矩阵运算，这样就可以通过成熟的GPU库来加速运算。其次再看内存消耗问题，$q(z_{mjk})$总共需要储存`m*j*k`个参数，如果有`1000`篇文档`10000`个词和`50`个主题，那么$q(z_{mjk})$将有`5亿`个元素，这在内存消耗上是不可接受的，在实现上我们只会在批量计算$\\theta_{mk}$和$\\psi_{kj}$参数时用到的部分$q(z_{mjk})$批量计算出来，并且一旦使用完毕立即丢弃。具体代码就不在这里贴了，完整的demo见[pLSA实现](https://github.com/EmbolismSoil/pLSA)\n\n## 总结\npLSA是概率隐语义主题模型中相对简单的一种，推导和实现都相对简单，回头看上面的算法过程，实际上只需要简单地计数迭代而已，所以pLSA非常适合在线学习。其实并非pLSA有此特点，事实上大多数生成模型都一样适合在线学习。不过pLSA的缺点也是非常明显的，**pLSA将文章建模时没有考虑文章词序**，也就是我们随机将一篇文章词打散，对于pLSA来说，其联合概率$p(\\bf w, \\bf z, \\bf d)$是不变的,这一点回头看式子$(2)$就知道。这意味着\"谁是你爸爸\"和\"你爸爸是谁\"这两句话在pLSA眼里看来是一样的，这种情况在短文本场景中尤其常见。但幸运的是，在长文本领域，*有研表究明，汉字的序顺并不能影阅响读*。不过pLSA近年来正在逐渐被更新颖复杂的LDA代替，但相对LDA来说pLSA结构简单，容易做大规模并行化，所以时至今日，pLSA在大规模文本挖掘领域依旧光耀夺目。\n\n最后，向Thomas Hofmann先生致敬，感谢先生为我们带来如此精妙的pLSA主题模型。\n\n## 参考文献\n[1] [ Probabilistic Latent Semantic Analysis](https://arxiv.org/pdf/1301.6705.pdf)\n[2] [Tutorial on Probablistic Latent Semantic Analysis](https://arxiv.org/pdf/1212.3900.pdf)","slug":"让机器读懂文章-pLSA模型推导及实现","published":1,"updated":"2019-07-10T18:27:27.391Z","_id":"cjxxkpq9m0003lutmdpgyidmx","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>人类读懂文章是一个很自然的行为，当我们读完一篇《背影》的时候，我们就可以知道这篇文章在写些什么，也就是我们说获得了这篇文章的相关知识。有了这些知识，我们就可以回答一些问题，例如:</p>\n<ol>\n<li>问：这篇文章写的主要内容是什么呢？<br> 答： 亲情、送别</li>\n<li>问：有类似《背影》这样的文章可以推荐的吗？<br> 答：龙应台-《送别》</li>\n</ol>\n<p>虽然上面的问答对任务对人类来说十分简单，但对于机器来说却并不容易。机器对自然语言(中文文本)的理解实际上并不是非常简单的事情，因为自然语言本身是一个高层抽象的概念，而机器只擅长处理量化的知识，例如说让机器记住向量$\\vec x=[1, 2, 3]$和$\\vec y=[4, 5, 6]$是十分容易的事情，而且可以轻易知道$\\vec x$和$\\vec y$的相似程度，这只需要计算其记录即可，于是我们对于向量来说就可以完成上面的问题2了。</p>\n<p>让我们重新揣摩一下人类读懂文章的过程，实际上我们并不需要背熟每一个字词，而是阅读完成之后再总结出这篇文章主要在写什么，也就是文章的主题。为了让机器能理解文章，我们也需要把这些主题量化出来，形成类似$\\overrightarrow {topic}=[‘亲情’: 0.5, ‘送别’: 0.5]$的向量，这种能量化文章主题的模型，也就叫做<strong>主题模型</strong>了。</p>\n<p>在主题模型方面前人们已经做了很多工作，并且取得了非常不错的成效，其中影响较大的是一类模型叫做<strong>隐语义模型</strong>，而这类模型里面<strong>概率隐语义分析</strong>也就是本文所述的pLSA则是应用最成功的模型之一，同样成功的模型还有<strong>隐含狄利克雷分布</strong>，也就是大名鼎鼎的LDA主题模型，不过LDA与pLSA的思想一脉相承，只不过做了贝叶斯改造而已。</p>\n<h2 id=\"pLSA模型\"><a href=\"#pLSA模型\" class=\"headerlink\" title=\"pLSA模型\"></a>pLSA模型</h2><p>事实上pLSA是在对我们写一篇文章的行为建模，我们先揣摩朱自清先生写《背影》的行为。首先我朱先生敲定了今天要写一篇《背影》，然后他开始构思了这篇文章的主题为：亲情、送别，并且朱先生认为这两部分的内容都几乎同等重要，也就是: $[‘亲情’: 0.5, ‘送别’: 0.5]$，朱先生开始动笔，于是当朱先生写下</p>\n<blockquote>\n<p>我买几个橘子去，你就在此地，不要走动。</p>\n</blockquote>\n<p>实际上是朱先生先前构思好的亲情、父子、送别这三个中心思想在影响着朱先生写下了这段话。于是在这三个中心思想的影响下，朱先生写完了《背影》里面的所有词，而我们读者所谓的<strong>理解</strong>《背影》，实际上就是从我们看到的《背影》的所有词，推断出了朱先生构思的主题: $[‘亲情’: 0.5, ‘送别’: 0.5]$。而pLSA则只是用数学化的形式描述这个过程, 这样一个形式化的过程在pLSA的眼里是这样的：</p>\n<ol>\n<li>从分布$p(d_m)$上采样选择了一篇文章$d_m$</li>\n<li>对于文章$d_m$每一个词，从分布$p(z_k|d_m)$上采样一个生成一个主题$z_k$</li>\n<li>从分布$p(w_n|z_k)$上采样生成了一个词$w_n$</li>\n</ol>\n<p>这个模型可以用plate notation更加简洁地描述：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20181230011214553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTMyOTgzMDA=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"pLSA模型\"><br>图中的阴影部分的变量$d$和$w$对应着文章和文章的所有词，表示可观测的变量，$z$是观测不到的主题，我们称之为隐变量，两个框框左下角的$N$和$M$则分别表示$N$和$M$词独立重复试验。这个图所表达的文章生成过程跟上面的文字表述是一致的。</p>\n<p>这样写文章的模型是符合直觉的，但仔细推敲总觉得过于机械生硬，这样的机械式过程能写得出朱先生《背影》那样优秀的文章吗? </p>\n<blockquote>\n<p>如果无限多个猴子任意敲打打字机键，最终会写出大英博物馆的所有藏书 — 爱丁顿无限猴子理论</p>\n</blockquote>\n<p>一件小概率的事件在多次试验中必然发生，这就是为什么随机敲打键盘的猴子也能作的原因，于是上面问题答案自然是肯定的，pLSA这样合乎直觉的模型当然要比一只茫无目的敲打键盘的猴子更加具备写作天赋。</p>\n<p>我们读者需要阅读根据文章和文章的所有内容去推断文章的主题，而pLSA眼里则是根据可观测变量$w$和可观测变量$d$去推断隐变量$z$。我们可以通过海量的文章去解算出模型中的参数，也就是上文中的$p(z_k|p_m)$和$p(w_n|z_k)$两个分布，我们称之为<strong>文章主题分布</strong>和<strong>主题词分布</strong>。 而$p(z_k|d_m)$这个分布实际上就是文章$d_m$的主题分布，也就是我们前文所说的$[‘亲情’: 0.5, ‘送别’: 0.5]$这样的文章主题，这个分布就是我们就获取到关于文章的知识，它量化说明了文章$d_m$在说什么内容。至于模型参数解算的过程，这没什么不可以理解的，正如我定义了一个$y$的产生过程过$y=ax+b$, 当我拿到足够多的样本$y_0=0, y_1=1, y_2=2,….y_n=n$之后，实际上我可以将他们组成方程组解出合理的参数$a$、$b$和$x$来。</p>\n<p>行文至此，我们且对pLSA的求解按下不表，先来实际感受一下pLSA的作用。这里选择格林童话中的十几篇童话作为语料训练pLSA，然后分别从5个主题分布中取出的top3词语：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>topic-1</th>\n<th>topic-2</th>\n<th>topic-3</th>\n<th>topic-4</th>\n<th>topic-5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>wrong</td>\n<td>birds</td>\n<td>morning</td>\n<td>soldier</td>\n<td>good</td>\n</tr>\n<tr>\n<td>issue</td>\n<td>fox</td>\n<td>met</td>\n<td>king</td>\n<td>gave</td>\n</tr>\n<tr>\n<td>faith</td>\n<td>horse</td>\n<td>wood</td>\n<td>castle</td>\n<td>great</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到pLSA是可以正确推导出来主题分布的。</p>\n<h2 id=\"pLSA的EM算法推导\"><a href=\"#pLSA的EM算法推导\" class=\"headerlink\" title=\"pLSA的EM算法推导\"></a>pLSA的EM算法推导</h2><p>pLSA是一种含隐变量的生成模型，也就是概率化地描述了样本数据(文章)的生成并且包含隐藏变量的模型，对于这种模型可用MCMC或EM算法来求解。本文讲解的是pLSA的EM算法求解，这里并不打算讲解EM的具体推导，而是直接利用EM算法的结论来对pLSA模型求解，关于EM算法的内容读者可以自己网上搜罗一下资料，或者待我抽空再写一篇关于EM算法的文章。<br>在开始推导之前，我们先假设词库大小为$j$, 每篇文章都由词库中的词$w_j$构成。然后定义模型参数:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n\\theta_{mk}=p(z_k|d_m) \\\\\n\\psi_{kj} = p(w_j|z_k)\n\\end{aligned} \\tag{1}</script><p>根据EM算法的求解步骤，我们先根据plate notation写出联合分布:</p>\n<script type=\"math/tex; mode=display\">\n    p(\\bf w, \\bf z, \\bf d) = \\prod_m p(d_m) \\prod_n p(w_{mn}|z_{mn})p(z_{mn}|d_m) \\tag{2}</script><p>其中$d_m$表示第$m$篇文章， $w_{mn}$表示第$m$篇文章中的第$n$个词，$z_{mn}$表示第$m$篇文章中第$n$个词对应的主题。然后我们令给定模型参数下的主题后验证分布为：</p>\n<script type=\"math/tex; mode=display\">\n    Q(\\bf z; \\bf \\theta, \\bf \\psi) = p(\\bf z|\\bf d, \\bf w; \\bf \\theta, \\bf \\psi) \\tag{3}</script><p>于是可以启动EM算法当中的求期望步骤：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)] \\tag{4}</script><p>其中$q(z_{mnk})$表示在给定参数下的主题验分布，这里有:</p>\n<script type=\"math/tex; mode=display\">\nq(z_{mnk}) = p(z_k|d_m, w_n; \\theta_{mk}, \\psi_{kj}) = \\frac {p(d_m)\\theta_{mk}\\psi_{kn}}{\\sum_kp(d_m)\\theta_{mk}\\psi_{kn}} \\tag{5}</script><p>由于文章中总会出现许多重复词，例如文章$d_m$中第1个词和第$5$个词是一样的，那么就会有$w_{m1}=w_{m5}=w_j$那么对于式子$(4)$中$\\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)]$这部分，我们可以将文章$d_m$中重复出现的词对应的项合并成为$\\sum_j n_{mj}\\sum_kq(z_{mjk})ln[p(w_j|z_k)p(z_k|d_m)]$, 其中$n_{mj}$为文章$d_m$中词$w_j$出现的次数。于是我们重写式子$(4)$为：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\tag{6}</script><p>我们的目标是最大化式子$(6)$, 并且因为参数$\\bf \\theta$和$\\bf \\psi$是概率分布，所以有要约束$\\sum_k\\theta_{km}=1$和$\\sum_j{\\psi_{kj}} = 1$, 并且由于$p(d_m)$这个先验证分布可以设置为常数，这样我们去除与优化无关的常数项和增加了约束之后，就可以得到整个带约束的优化目标:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n    \\max \\limits_{\\theta_{mk}, \\psi_{kj}}   \\quad & \\sum_m \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\\\\n    \\bf{s.t.} \\quad & \\sum_{k}\\theta_{mk}=1, m=1,2,3,...,M \\\\\n    & \\sum_{j} \\psi_{kj} = 1, k=1,2,3,...,K\n\\end{aligned} \\tag{7}</script><p>这个带约束的优化目标直接使用拉格朗日乘子法：</p>\n<script type=\"math/tex; mode=display\">\n    L(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha) = \\sum_m \\sum_j n_{mj} \\sum_k  q(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) + \\sum_m {\\lambda_m} (1-\\sum_k\\theta_{mk}) + \\sum_k \\alpha_{k} (1-\\sum_j {\\psi_{kj}}) \\tag{8}</script><p>于是可以对参数$\\theta_{mk}$求导并令其为0:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{ \\partial L(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha)}{\\partial \\theta_{mk}} = \\frac{ \\sum_jn_{mj}q(z_{mjk})}{\\theta_{mk}} - \\lambda_m = 0 \\\\\n \\lambda_m \\theta_{mk} ={ \\sum_jn_{mj}q(z_{mjk})}  \\tag{9}</script><p>式子(9)左右两边对$k$求和得到:</p>\n<script type=\"math/tex; mode=display\">\n\\lambda_m \\sum_k \\theta_{mk} = \\sum_j{n_{mj}} \\sum_{z}q(z_{mjk}) \\\\\n\\lambda_m = \\sum_j {n_{mj}} = N_m \\tag{10}</script><p>上述式子(10)中$N_m$表示文章$d_m$的总词数，将式子$(10)$代回式(9)可以得到:</p>\n<script type=\"math/tex; mode=display\">\n\\theta_{mk} = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\tag{11}</script><p>同样地我们对参数$\\psi_{kj}$故技重施:</p>\n<script type=\"math/tex; mode=display\">\n\\frac {\\partial L(\\bf \\theta, \\bf \\psi,\\bf \\lambda, \\bf \\alpha)}{\\partial \\psi_{kj}} = \\frac{\\sum_m n_{mj}q(z_{mjk})}{\\psi_{kj}} - \\alpha_k = 0 \\\\\n\\alpha_k \\psi_{kj} = \\sum_m n_{mj}q(z_{mjk}) \\tag{12}</script><p>式子(12)左右两边对$j$求和得到:</p>\n<script type=\"math/tex; mode=display\">\n\\alpha_k \\sum_{j} \\psi_{kj} = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\\\\n\\alpha_k = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\tag{13}</script><p>将式子代回$(12)$得到：</p>\n<script type=\"math/tex; mode=display\">\n\\psi_{kj} = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})} \\tag{14}</script><p>至此，pLSA参数求解完毕。根据参数更新的规则，我们设在EM算法迭代运行的过程中，第$i$轮的参数为$\\theta_{mk}^i$和$\\psi_{kj}^i$。于是整个pLSA的EM算法可以归纳为：</p>\n<ol>\n<li>随机初始化参数$\\theta_{mk}^0$和$\\psi_{kj}^0$</li>\n<li>开始第$i\\in[1, 2, 3…n]$轮迭代:<br> a. 求$q(z_{mjk})=\\frac {p(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}{\\sum_kp(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}$<br> b. 更新参数<script type=\"math/tex; mode=display\">\n     \\theta_{mk}^i = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\\\\n     \\psi_{kj}^i = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})}</script> c. 若参数收敛，则退出迭代，否则返回<code>a</code>继续迭代</li>\n<li>输出模型参数$\\bf \\theta$和$\\bf \\psi$</li>\n</ol>\n<h2 id=\"pLSA的实现\"><a href=\"#pLSA的实现\" class=\"headerlink\" title=\"pLSA的实现\"></a>pLSA的实现</h2><p>从上边的式子来看pLSA是相对比较容易实现的，但是高效地实现还需要一些技巧。首先看式(14)的分母，存在一个二阶求和的过程，如果语料库中有<code>1000</code>篇文档，<code>10000</code>个词，那么就要进行一千万次运算，这样显然必须要用并行批量计算的方式来加速，在实现上我们会将涉及的所有运算都转换为矩阵运算，这样就可以通过成熟的GPU库来加速运算。其次再看内存消耗问题，$q(z_{mjk})$总共需要储存<code>m*j*k</code>个参数，如果有<code>1000</code>篇文档<code>10000</code>个词和<code>50</code>个主题，那么$q(z_{mjk})$将有<code>5亿</code>个元素，这在内存消耗上是不可接受的，在实现上我们只会在批量计算$\\theta_{mk}$和$\\psi_{kj}$参数时用到的部分$q(z_{mjk})$批量计算出来，并且一旦使用完毕立即丢弃。具体代码就不在这里贴了，完整的demo见<a href=\"https://github.com/EmbolismSoil/pLSA\" target=\"_blank\" rel=\"noopener\">pLSA实现</a></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>pLSA是概率隐语义主题模型中相对简单的一种，推导和实现都相对简单，回头看上面的算法过程，实际上只需要简单地计数迭代而已，所以pLSA非常适合在线学习。其实并非pLSA有此特点，事实上大多数生成模型都一样适合在线学习。不过pLSA的缺点也是非常明显的，<strong>pLSA将文章建模时没有考虑文章词序</strong>，也就是我们随机将一篇文章词打散，对于pLSA来说，其联合概率$p(\\bf w, \\bf z, \\bf d)$是不变的,这一点回头看式子$(2)$就知道。这意味着”谁是你爸爸”和”你爸爸是谁”这两句话在pLSA眼里看来是一样的，这种情况在短文本场景中尤其常见。但幸运的是，在长文本领域，<em>有研表究明，汉字的序顺并不能影阅响读</em>。不过pLSA近年来正在逐渐被更新颖复杂的LDA代替，但相对LDA来说pLSA结构简单，容易做大规模并行化，所以时至今日，pLSA在大规模文本挖掘领域依旧光耀夺目。</p>\n<p>最后，向Thomas Hofmann先生致敬，感谢先生为我们带来如此精妙的pLSA主题模型。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p>[1] <a href=\"https://arxiv.org/pdf/1301.6705.pdf\" target=\"_blank\" rel=\"noopener\"> Probabilistic Latent Semantic Analysis</a><br>[2] <a href=\"https://arxiv.org/pdf/1212.3900.pdf\" target=\"_blank\" rel=\"noopener\">Tutorial on Probablistic Latent Semantic Analysis</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>人类读懂文章是一个很自然的行为，当我们读完一篇《背影》的时候，我们就可以知道这篇文章在写些什么，也就是我们说获得了这篇文章的相关知识。有了这些知识，我们就可以回答一些问题，例如:</p>\n<ol>\n<li>问：这篇文章写的主要内容是什么呢？<br> 答： 亲情、送别</li>\n<li>问：有类似《背影》这样的文章可以推荐的吗？<br> 答：龙应台-《送别》</li>\n</ol>\n<p>虽然上面的问答对任务对人类来说十分简单，但对于机器来说却并不容易。机器对自然语言(中文文本)的理解实际上并不是非常简单的事情，因为自然语言本身是一个高层抽象的概念，而机器只擅长处理量化的知识，例如说让机器记住向量$\\vec x=[1, 2, 3]$和$\\vec y=[4, 5, 6]$是十分容易的事情，而且可以轻易知道$\\vec x$和$\\vec y$的相似程度，这只需要计算其记录即可，于是我们对于向量来说就可以完成上面的问题2了。</p>\n<p>让我们重新揣摩一下人类读懂文章的过程，实际上我们并不需要背熟每一个字词，而是阅读完成之后再总结出这篇文章主要在写什么，也就是文章的主题。为了让机器能理解文章，我们也需要把这些主题量化出来，形成类似$\\overrightarrow {topic}=[‘亲情’: 0.5, ‘送别’: 0.5]$的向量，这种能量化文章主题的模型，也就叫做<strong>主题模型</strong>了。</p>\n<p>在主题模型方面前人们已经做了很多工作，并且取得了非常不错的成效，其中影响较大的是一类模型叫做<strong>隐语义模型</strong>，而这类模型里面<strong>概率隐语义分析</strong>也就是本文所述的pLSA则是应用最成功的模型之一，同样成功的模型还有<strong>隐含狄利克雷分布</strong>，也就是大名鼎鼎的LDA主题模型，不过LDA与pLSA的思想一脉相承，只不过做了贝叶斯改造而已。</p>\n<h2 id=\"pLSA模型\"><a href=\"#pLSA模型\" class=\"headerlink\" title=\"pLSA模型\"></a>pLSA模型</h2><p>事实上pLSA是在对我们写一篇文章的行为建模，我们先揣摩朱自清先生写《背影》的行为。首先我朱先生敲定了今天要写一篇《背影》，然后他开始构思了这篇文章的主题为：亲情、送别，并且朱先生认为这两部分的内容都几乎同等重要，也就是: $[‘亲情’: 0.5, ‘送别’: 0.5]$，朱先生开始动笔，于是当朱先生写下</p>\n<blockquote>\n<p>我买几个橘子去，你就在此地，不要走动。</p>\n</blockquote>\n<p>实际上是朱先生先前构思好的亲情、父子、送别这三个中心思想在影响着朱先生写下了这段话。于是在这三个中心思想的影响下，朱先生写完了《背影》里面的所有词，而我们读者所谓的<strong>理解</strong>《背影》，实际上就是从我们看到的《背影》的所有词，推断出了朱先生构思的主题: $[‘亲情’: 0.5, ‘送别’: 0.5]$。而pLSA则只是用数学化的形式描述这个过程, 这样一个形式化的过程在pLSA的眼里是这样的：</p>\n<ol>\n<li>从分布$p(d_m)$上采样选择了一篇文章$d_m$</li>\n<li>对于文章$d_m$每一个词，从分布$p(z_k|d_m)$上采样一个生成一个主题$z_k$</li>\n<li>从分布$p(w_n|z_k)$上采样生成了一个词$w_n$</li>\n</ol>\n<p>这个模型可以用plate notation更加简洁地描述：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20181230011214553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTMyOTgzMDA=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"pLSA模型\"><br>图中的阴影部分的变量$d$和$w$对应着文章和文章的所有词，表示可观测的变量，$z$是观测不到的主题，我们称之为隐变量，两个框框左下角的$N$和$M$则分别表示$N$和$M$词独立重复试验。这个图所表达的文章生成过程跟上面的文字表述是一致的。</p>\n<p>这样写文章的模型是符合直觉的，但仔细推敲总觉得过于机械生硬，这样的机械式过程能写得出朱先生《背影》那样优秀的文章吗? </p>\n<blockquote>\n<p>如果无限多个猴子任意敲打打字机键，最终会写出大英博物馆的所有藏书 — 爱丁顿无限猴子理论</p>\n</blockquote>\n<p>一件小概率的事件在多次试验中必然发生，这就是为什么随机敲打键盘的猴子也能作的原因，于是上面问题答案自然是肯定的，pLSA这样合乎直觉的模型当然要比一只茫无目的敲打键盘的猴子更加具备写作天赋。</p>\n<p>我们读者需要阅读根据文章和文章的所有内容去推断文章的主题，而pLSA眼里则是根据可观测变量$w$和可观测变量$d$去推断隐变量$z$。我们可以通过海量的文章去解算出模型中的参数，也就是上文中的$p(z_k|p_m)$和$p(w_n|z_k)$两个分布，我们称之为<strong>文章主题分布</strong>和<strong>主题词分布</strong>。 而$p(z_k|d_m)$这个分布实际上就是文章$d_m$的主题分布，也就是我们前文所说的$[‘亲情’: 0.5, ‘送别’: 0.5]$这样的文章主题，这个分布就是我们就获取到关于文章的知识，它量化说明了文章$d_m$在说什么内容。至于模型参数解算的过程，这没什么不可以理解的，正如我定义了一个$y$的产生过程过$y=ax+b$, 当我拿到足够多的样本$y_0=0, y_1=1, y_2=2,….y_n=n$之后，实际上我可以将他们组成方程组解出合理的参数$a$、$b$和$x$来。</p>\n<p>行文至此，我们且对pLSA的求解按下不表，先来实际感受一下pLSA的作用。这里选择格林童话中的十几篇童话作为语料训练pLSA，然后分别从5个主题分布中取出的top3词语：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>topic-1</th>\n<th>topic-2</th>\n<th>topic-3</th>\n<th>topic-4</th>\n<th>topic-5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>wrong</td>\n<td>birds</td>\n<td>morning</td>\n<td>soldier</td>\n<td>good</td>\n</tr>\n<tr>\n<td>issue</td>\n<td>fox</td>\n<td>met</td>\n<td>king</td>\n<td>gave</td>\n</tr>\n<tr>\n<td>faith</td>\n<td>horse</td>\n<td>wood</td>\n<td>castle</td>\n<td>great</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到pLSA是可以正确推导出来主题分布的。</p>\n<h2 id=\"pLSA的EM算法推导\"><a href=\"#pLSA的EM算法推导\" class=\"headerlink\" title=\"pLSA的EM算法推导\"></a>pLSA的EM算法推导</h2><p>pLSA是一种含隐变量的生成模型，也就是概率化地描述了样本数据(文章)的生成并且包含隐藏变量的模型，对于这种模型可用MCMC或EM算法来求解。本文讲解的是pLSA的EM算法求解，这里并不打算讲解EM的具体推导，而是直接利用EM算法的结论来对pLSA模型求解，关于EM算法的内容读者可以自己网上搜罗一下资料，或者待我抽空再写一篇关于EM算法的文章。<br>在开始推导之前，我们先假设词库大小为$j$, 每篇文章都由词库中的词$w_j$构成。然后定义模型参数:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n\\theta_{mk}=p(z_k|d_m) \\\\\n\\psi_{kj} = p(w_j|z_k)\n\\end{aligned} \\tag{1}</script><p>根据EM算法的求解步骤，我们先根据plate notation写出联合分布:</p>\n<script type=\"math/tex; mode=display\">\n    p(\\bf w, \\bf z, \\bf d) = \\prod_m p(d_m) \\prod_n p(w_{mn}|z_{mn})p(z_{mn}|d_m) \\tag{2}</script><p>其中$d_m$表示第$m$篇文章， $w_{mn}$表示第$m$篇文章中的第$n$个词，$z_{mn}$表示第$m$篇文章中第$n$个词对应的主题。然后我们令给定模型参数下的主题后验证分布为：</p>\n<script type=\"math/tex; mode=display\">\n    Q(\\bf z; \\bf \\theta, \\bf \\psi) = p(\\bf z|\\bf d, \\bf w; \\bf \\theta, \\bf \\psi) \\tag{3}</script><p>于是可以启动EM算法当中的求期望步骤：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)] \\tag{4}</script><p>其中$q(z_{mnk})$表示在给定参数下的主题验分布，这里有:</p>\n<script type=\"math/tex; mode=display\">\nq(z_{mnk}) = p(z_k|d_m, w_n; \\theta_{mk}, \\psi_{kj}) = \\frac {p(d_m)\\theta_{mk}\\psi_{kn}}{\\sum_kp(d_m)\\theta_{mk}\\psi_{kn}} \\tag{5}</script><p>由于文章中总会出现许多重复词，例如文章$d_m$中第1个词和第$5$个词是一样的，那么就会有$w_{m1}=w_{m5}=w_j$那么对于式子$(4)$中$\\sum_n \\sum_kq(z_{mnk})ln[p(w_{mn}|z_k)p(z_k|d_m)]$这部分，我们可以将文章$d_m$中重复出现的词对应的项合并成为$\\sum_j n_{mj}\\sum_kq(z_{mjk})ln[p(w_j|z_k)p(z_k|d_m)]$, 其中$n_{mj}$为文章$d_m$中词$w_j$出现的次数。于是我们重写式子$(4)$为：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_{\\bf z} {Q(\\bf z)lnp(\\bf w, \\bf z, \\bf w)} = \\sum_mlnp(d_m) \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\tag{6}</script><p>我们的目标是最大化式子$(6)$, 并且因为参数$\\bf \\theta$和$\\bf \\psi$是概率分布，所以有要约束$\\sum_k\\theta_{km}=1$和$\\sum_j{\\psi_{kj}} = 1$, 并且由于$p(d_m)$这个先验证分布可以设置为常数，这样我们去除与优化无关的常数项和增加了约束之后，就可以得到整个带约束的优化目标:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n    \\max \\limits_{\\theta_{mk}, \\psi_{kj}}   \\quad & \\sum_m \\sum_j n_{mj}\\sum_kq(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) \\\\\n    \\bf{s.t.} \\quad & \\sum_{k}\\theta_{mk}=1, m=1,2,3,...,M \\\\\n    & \\sum_{j} \\psi_{kj} = 1, k=1,2,3,...,K\n\\end{aligned} \\tag{7}</script><p>这个带约束的优化目标直接使用拉格朗日乘子法：</p>\n<script type=\"math/tex; mode=display\">\n    L(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha) = \\sum_m \\sum_j n_{mj} \\sum_k  q(z_{mjk})ln(\\theta_{mk}\\psi_{kj}) + \\sum_m {\\lambda_m} (1-\\sum_k\\theta_{mk}) + \\sum_k \\alpha_{k} (1-\\sum_j {\\psi_{kj}}) \\tag{8}</script><p>于是可以对参数$\\theta_{mk}$求导并令其为0:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{ \\partial L(\\bf \\theta, \\bf \\psi, \\bf \\lambda, \\bf \\alpha)}{\\partial \\theta_{mk}} = \\frac{ \\sum_jn_{mj}q(z_{mjk})}{\\theta_{mk}} - \\lambda_m = 0 \\\\\n \\lambda_m \\theta_{mk} ={ \\sum_jn_{mj}q(z_{mjk})}  \\tag{9}</script><p>式子(9)左右两边对$k$求和得到:</p>\n<script type=\"math/tex; mode=display\">\n\\lambda_m \\sum_k \\theta_{mk} = \\sum_j{n_{mj}} \\sum_{z}q(z_{mjk}) \\\\\n\\lambda_m = \\sum_j {n_{mj}} = N_m \\tag{10}</script><p>上述式子(10)中$N_m$表示文章$d_m$的总词数，将式子$(10)$代回式(9)可以得到:</p>\n<script type=\"math/tex; mode=display\">\n\\theta_{mk} = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\tag{11}</script><p>同样地我们对参数$\\psi_{kj}$故技重施:</p>\n<script type=\"math/tex; mode=display\">\n\\frac {\\partial L(\\bf \\theta, \\bf \\psi,\\bf \\lambda, \\bf \\alpha)}{\\partial \\psi_{kj}} = \\frac{\\sum_m n_{mj}q(z_{mjk})}{\\psi_{kj}} - \\alpha_k = 0 \\\\\n\\alpha_k \\psi_{kj} = \\sum_m n_{mj}q(z_{mjk}) \\tag{12}</script><p>式子(12)左右两边对$j$求和得到:</p>\n<script type=\"math/tex; mode=display\">\n\\alpha_k \\sum_{j} \\psi_{kj} = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\\\\n\\alpha_k = \\sum_m \\sum_j n_{mj} q(z_{mjk}) \\tag{13}</script><p>将式子代回$(12)$得到：</p>\n<script type=\"math/tex; mode=display\">\n\\psi_{kj} = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})} \\tag{14}</script><p>至此，pLSA参数求解完毕。根据参数更新的规则，我们设在EM算法迭代运行的过程中，第$i$轮的参数为$\\theta_{mk}^i$和$\\psi_{kj}^i$。于是整个pLSA的EM算法可以归纳为：</p>\n<ol>\n<li>随机初始化参数$\\theta_{mk}^0$和$\\psi_{kj}^0$</li>\n<li>开始第$i\\in[1, 2, 3…n]$轮迭代:<br> a. 求$q(z_{mjk})=\\frac {p(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}{\\sum_kp(d_m)\\theta_{mk}^{i-1}\\psi_{kj}^{i-1}}$<br> b. 更新参数<script type=\"math/tex; mode=display\">\n     \\theta_{mk}^i = \\frac {\\sum_j n_{mj}q(z_{mjk})}{N_m} \\\\\n     \\psi_{kj}^i = \\frac { \\sum_m n_{mj}q(z_{mjk})}{ \\sum_m \\sum_j n_{mj} q(z_{mjk})}</script> c. 若参数收敛，则退出迭代，否则返回<code>a</code>继续迭代</li>\n<li>输出模型参数$\\bf \\theta$和$\\bf \\psi$</li>\n</ol>\n<h2 id=\"pLSA的实现\"><a href=\"#pLSA的实现\" class=\"headerlink\" title=\"pLSA的实现\"></a>pLSA的实现</h2><p>从上边的式子来看pLSA是相对比较容易实现的，但是高效地实现还需要一些技巧。首先看式(14)的分母，存在一个二阶求和的过程，如果语料库中有<code>1000</code>篇文档，<code>10000</code>个词，那么就要进行一千万次运算，这样显然必须要用并行批量计算的方式来加速，在实现上我们会将涉及的所有运算都转换为矩阵运算，这样就可以通过成熟的GPU库来加速运算。其次再看内存消耗问题，$q(z_{mjk})$总共需要储存<code>m*j*k</code>个参数，如果有<code>1000</code>篇文档<code>10000</code>个词和<code>50</code>个主题，那么$q(z_{mjk})$将有<code>5亿</code>个元素，这在内存消耗上是不可接受的，在实现上我们只会在批量计算$\\theta_{mk}$和$\\psi_{kj}$参数时用到的部分$q(z_{mjk})$批量计算出来，并且一旦使用完毕立即丢弃。具体代码就不在这里贴了，完整的demo见<a href=\"https://github.com/EmbolismSoil/pLSA\" target=\"_blank\" rel=\"noopener\">pLSA实现</a></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>pLSA是概率隐语义主题模型中相对简单的一种，推导和实现都相对简单，回头看上面的算法过程，实际上只需要简单地计数迭代而已，所以pLSA非常适合在线学习。其实并非pLSA有此特点，事实上大多数生成模型都一样适合在线学习。不过pLSA的缺点也是非常明显的，<strong>pLSA将文章建模时没有考虑文章词序</strong>，也就是我们随机将一篇文章词打散，对于pLSA来说，其联合概率$p(\\bf w, \\bf z, \\bf d)$是不变的,这一点回头看式子$(2)$就知道。这意味着”谁是你爸爸”和”你爸爸是谁”这两句话在pLSA眼里看来是一样的，这种情况在短文本场景中尤其常见。但幸运的是，在长文本领域，<em>有研表究明，汉字的序顺并不能影阅响读</em>。不过pLSA近年来正在逐渐被更新颖复杂的LDA代替，但相对LDA来说pLSA结构简单，容易做大规模并行化，所以时至今日，pLSA在大规模文本挖掘领域依旧光耀夺目。</p>\n<p>最后，向Thomas Hofmann先生致敬，感谢先生为我们带来如此精妙的pLSA主题模型。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p>[1] <a href=\"https://arxiv.org/pdf/1301.6705.pdf\" target=\"_blank\" rel=\"noopener\"> Probabilistic Latent Semantic Analysis</a><br>[2] <a href=\"https://arxiv.org/pdf/1212.3900.pdf\" target=\"_blank\" rel=\"noopener\">Tutorial on Probablistic Latent Semantic Analysis</a></p>\n"}],"PostAsset":[{"_id":"source/_posts/svm从原理到实现/svm_model.gif","slug":"svm_model.gif","post":"cjxxkpq8a0000lutmu63nbpqh","modified":0,"renderable":0},{"_id":"source/_posts/svm从原理到实现/svm_model.png","slug":"svm_model.png","post":"cjxxkpq8a0000lutmu63nbpqh","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cjxxkpq8a0000lutmu63nbpqh","category_id":"cjxxkpq9k0001lutmomb1pl6g","_id":"cjxxkpqaz000blutmvckfll7r"},{"post_id":"cjxxkpq8a0000lutmu63nbpqh","category_id":"cjxxkpqap0005lutmi7hc4vfz","_id":"cjxxkpqaz000clutm2f6rylub"},{"post_id":"cjxxkpq9m0003lutmdpgyidmx","category_id":"cjxxkqxrs0002mvtmxuzkmkbu","_id":"cjxxkqxrt0003mvtmc764zucf"}],"PostTag":[{"post_id":"cjxxkpq8a0000lutmu63nbpqh","tag_id":"cjxxkpq9l0002lutmc71o9x3c","_id":"cjxxkpqaq0006lutmm47zsktm"},{"post_id":"cjxxkpq8a0000lutmu63nbpqh","tag_id":"cjxxkpq9n0004lutmdwj7q840","_id":"cjxxkpqaq0007lutma4vanxxa"},{"post_id":"cjxxkpq9m0003lutmdpgyidmx","tag_id":"cjxxkqsj60000mvtm1bybcoft","_id":"cjxxkqsj80001mvtmywgbhakg"}],"Tag":[{"name":"算法","_id":"cjxxkpq9l0002lutmc71o9x3c"},{"name":"机器学习","_id":"cjxxkpq9n0004lutmdwj7q840"},{"name":"自然语言处理","_id":"cjxxkqsj60000mvtm1bybcoft"}]}}